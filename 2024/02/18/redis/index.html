<!DOCTYPE html>
<html>
  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <meta name="description" content="要有一个从输入到输出的过程">
  <meta name="keyword" content="hexo-theme, vuejs">
  
    <link rel="shortcut icon" href="/css/images/logo.png">
  
  <title>
    
      Redis | CQ&#39;s Blog
    
  </title>
  <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/tomorrow.min.css" rel="stylesheet">
  
<link rel="stylesheet" href="/css/style.css">

  
  <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/geopattern/1.2.3/js/geopattern.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.js"></script>
  
  
  
  
    <!-- MathJax support START -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- MathJax support END -->
  


  
  
    
<script src="/js/local-search.js"></script>


<meta name="generator" content="Hexo 5.4.2"></head>
<div class="wechat-share">
  <img src="/css/images/logo.png" />
</div>
  <body>
    <header class="header fixed-header">
  <div class="header-container">
    <a class="home-link" href="/">
      <div class="logo"></div>
      <span>CQ's Blog</span>
    </a>
    <ul class="right-list">
      
        <li class="list-item">
          
            <a href="/" class="item-link">Home</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/" class="item-link">Categories</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/records" class="item-link">Records</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/scratches/" class="item-link">Scratches</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/archives/" class="item-link">Archives</a>
          
        </li>
      
      
        <li class="menu-item menu-item-search right-list">
    <a role="button" class="popup-trigger">
        <i class="fa fa-search fa-fw"></i>
    </a>
</li>
      
    </ul>
    <div class="menu">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </div>
    <div class="menu-mask">
      <ul class="menu-list">
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">Home</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">Categories</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/records" class="menu-link">Records</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/scratches/" class="menu-link">Scratches</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/archives/" class="menu-link">Archives</a>
            
          </li>
        
      </ul>
    </div>
    
      <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
            <span class="search-icon">
                <i class="fa fa-search"></i>
            </span>
            <div class="search-input-container">
                <input autocomplete="off" autocapitalize="off"
                    placeholder="Please enter your keyword(s) to search." spellcheck="false"
                    type="search" class="search-input">
            </div>
            <span class="popup-btn-close">
                <i class="fa fa-times-circle"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>
    
  </div>
</header>

    <div id="article-banner">
  <h2>Redis</h2>
  <!--<p class="post-date">2024-02-18</p>
  <div class="arrow-down">
    <a href="javascript:;"></a>
  </div>-->
</div>
<main class="app-body flex-box">
  <!-- Article START -->
  <article class="post-article">
    <section class="markdown-content"><p>Redis 是一个内存数据库，设计目标是高性能、高可用、高可扩展性以及最终一致性。</p>
<h1 id="1、模式"><a href="#1、模式" class="headerlink" title="1、模式"></a>1、模式</h1><h2 id="1-1-集群模式"><a href="#1-1-集群模式" class="headerlink" title="1.1 集群模式"></a>1.1 集群模式</h2><p>Redis 主要有三种集群模式</p>
<ul>
<li>主从复制模式<ul>
<li>主从复制模式是 Redis 最简单的集群模式，包括一个主节点和多个从节点，主节点会负责所有的读写操作，从节点作为主节点的数据副本只能负责读操作，当主节点发生故障时，需要手动将一个从节点升级为主节点，实现故障转移，这种模式主要是为了解决单点故障问题</li>
<li>主从复制模式提供了数据备份功能，简单易用，适用于读多写少的场景，并且具有很好的扩展性，可以通过增加更多的从节点来让集群的读能力不断提升，但是故障转移时需要人工介入，没有容错和恢复机制，任意节点的故障都会导致客户端部分读写请求失败</li>
</ul>
</li>
<li>哨兵模式<ul>
<li>哨兵模式是在主从复制的基础上增加了哨兵节点，哨兵节点是一种特殊的 Redis 节点，用于监控主节点和从节点的状态，当主节点发生故障时，哨兵节点可以自动进行故障转移，即选择一个合适的从节点升级为主节点，并通知其他从节点和应用程序进行更新，这种模式主要是为了解决自动容错和恢复问题</li>
<li>每个 Redis 实例都可以作为哨兵节点，通常需要部署多个哨兵节点来确保故障转移的可靠性，哨兵节点定期向所有主节点和从节点发送 PING 命令，如果在指定时间内未收到 PONG 响应，哨兵节点则将该节点标记为主观下线，如果一个节点被多数哨兵节点标记为主观下线，那么该节点被标记为客观下线</li>
<li>当主节点被标记为客观下线时，哨兵节点会触发故障转移过程，它会从所有健康的从节点中选举一个新的主节点，并将所有从节点切换到新的主节点，哨兵节点可以通过发布订阅功能来通知客户端有关主节点状态变化的消息，客户端收到消息后自行更新配置，将新的主节点信息应用于连接池，实现自动故障转移</li>
</ul>
</li>
<li>Redis Cluster 模式<ul>
<li>Redis Cluster 模式是 Redis 推荐的分布式集群解决方案，会将数据自动划分为多个数据分片，每个分片都有一个主节点和多个从节点，每个节点都可以单独对外提供读写服务，采用主从复制模式来提供高可用性，采用哨兵模式来提供故障转移</li>
<li>数据分片是将整个数据集划分为固定数量（2^14 = 16384）个槽，每个数据都能唯一地被映射到一个槽位上，心跳数据包含了所有的原始槽配置，16384 个槽位大约需要 2K 的空间，Redis Cluster 会将主节点控制在 1000 个以下，并将所有槽位尽量均匀地分给这些主节点（一个主节点可能会负责多个槽）</li>
<li>Redis Cluster 模式是适用于大规模应用的解决方案，能够自动管理数据分片和故障转移，不存在单点故障，减少了运维负担，提供了更好的横向扩展和容错能力，具备高性能、高吞吐量、高可用性以及高数据冗余</li>
</ul>
</li>
</ul>
<p>分布式 Redis 集群默认采用异步复制，即便可以使用 WAIT 命令对特定数据进行同步复制，但 WAIT 仅能确保数据在 Redis 实例中有指定数量的副本被确认，依旧不能将一组 Redis 实例转变为强一致性的分布式系统，因此 Redis 集群无法保证强一致性。</p>
<h2 id="1-2-通信协议"><a href="#1-2-通信协议" class="headerlink" title="1.2 通信协议"></a>1.2 通信协议</h2><ul>
<li>Redis 采用自己设计的一种基于 TCP 协议的文本协议（Redis Serialization Protocol, RESP）进行客户端与服务端之间的通信</li>
<li>RESP 的每条请求命令由多个参数组成，命令名称就是第一个参数，RESP 的请求和响应都以<code>\r\n</code>作为分隔符，简单、高效、易于解析</li>
<li>除了基本的 GET、SET 命令操作，Redis 还支持事务、Lua 脚本、管道等高级功能，这些功能都是基于 RESP 实现的</li>
</ul>
<h2 id="1-3-并发模型"><a href="#1-3-并发模型" class="headerlink" title="1.3 并发模型"></a>1.3 并发模型</h2><ul>
<li>Redis 操作基本都是基于内存的，基本不存在磁盘 I/O，几乎不存在 CPU 资源浪费，无需通过多线程技术来提升 CPU 利用率，因此 Redis 使用复杂度更低的单线程处理数据请求即可，单线程是指 Redis 只有网络请求模块和数据操作模块是单线程的，其他的诸如持久化模块、集群支撑模块等是多线程的）</li>
<li>在单线程的基础上，Redis 还采用 I/O 多路复用来通过单个线程同时处理多个客户端连接，提升了 I/O 利用率，随着业务 QPS 增大，由于 I/O 多路复用本质上是同步阻塞型 I/O，此时，限制 Redis 的性能瓶颈就是网络 I/O</li>
<li>在 Redis 6.0 中，引入了多线程机制来减少了网络 I/O 等待，也更加充分地利用了 CPU 多核优势，该多线程机制仅针对网络请求和网络响应，数据的读写操作仍然是单线程处理的，因此并不会存在并发问题</li>
</ul>
<h2 id="1-4-事务机制"><a href="#1-4-事务机制" class="headerlink" title="1.4 事务机制"></a>1.4 事务机制</h2><ul>
<li>Redis 事务的主要目的是保证多个命令执行的并发原子性，即多个命令操作不可拆分，不会被打断</li>
<li>Redis 事务不支持回滚，在事务执行过程中发生错误会继续执行剩下的命令，因此无法保证数据库事务原子性</li>
<li>不支持回滚是因为回滚会对 Redis 的设计简洁性和使用性能产生重大影响，且 Redis 一般用作缓存，而不是作为需要处理复杂事务的关系型数据库，Redis 的事务执行出错的原因应当是在编码阶段解决的，不应该在执行过程中出现，不应该引入回滚机制来处理执行错误</li>
</ul>
<h2 id="1-5-原子操作"><a href="#1-5-原子操作" class="headerlink" title="1.5 原子操作"></a>1.5 原子操作</h2><ul>
<li>原子性执行 Lua 脚本<ul>
<li>Lua 是一种高效、轻量、小巧、可扩展的脚本语言，可以在多种操作系统上运行，设计目的是嵌入应用程序中，为应用程序提供灵活的扩展和定制功能，在功能上完全可以取代 Shell、Perl</li>
<li>Redis 会将 Lua 脚本封装成一个单独的事务，这个单独的事务在 Redis 服务器运行过程中，新的客户端请求会被暂存起来直到 Lua 脚本处理完毕后才会恢复请求，也就是说 Lua 脚本的执行不可拆分，执行中间不会被其他命令插入</li>
<li>如果 Lua 脚本中的命令产生错误，事务不会回滚，即 Redis 仅保证 Lua 脚本执行的并发原子性，但不保证事务原子性</li>
</ul>
</li>
<li>原子性执行命令<ul>
<li>Redis 中的所有命令都是在主线程中顺序执行的，每个命令在执行时不会被其他命令打断，因此所有命令的执行都可以保证并发原子性</li>
<li>虽然单个命令本身是原子性的，但是在实际应用中，多个命令组合可能会导致数据一致性问题，这种情况下需要通过 Redis 事务或分布式锁来保证数据的一致性</li>
</ul>
</li>
</ul>
<h2 id="1-6-Pipeline-机制"><a href="#1-6-Pipeline-机制" class="headerlink" title="1.6 Pipeline 机制"></a>1.6 Pipeline 机制</h2><p>在没有 Pipeline 时，每执行一个 Redis 命令，客户端都需要等到服务响应之后才能发送下一个命令，这种往返通信在网络延迟较高的环境中会显著影响性能，Redis 的 Pipeline 机制主要用于在单个请求/响应周期内执行多个命令，是一种用于优化网络延迟的技术。</p>
<p>在 Pipeline 模式下，客户端可以一次性发送多个命令到 Redis 服务器，无需等待每个命令的响应，Redis 服务器会依次执行这批命令并一次性返回响应。</p>
<h1 id="2、存储"><a href="#2、存储" class="headerlink" title="2、存储"></a>2、存储</h1><h2 id="2-1-内存管理"><a href="#2-1-内存管理" class="headerlink" title="2.1 内存管理"></a>2.1 内存管理</h2><ul>
<li>Redis 将数据存储在内存中，内存的数据读写本身就比磁盘更快，Redis 还采用一些复杂的内存管理方式，也支持很多内存优化策略</li>
<li>Redis 的虚拟内存机制会在 Redis 使用的内存超过了指定阈值时，将部分不常用的键值对转移到磁盘上，而在需要访问被转移到磁盘上的数据时，又将数据读取到内存中，虚拟内存机制虽然可以节省内存，但同时也会带来一定的性能损失，在实际应用中应该根据具体的应用场景和硬件条件进行调整</li>
<li>Redis 的内存淘汰策略用于在内存满了之后决定哪些 key 被删除，策略如下<ul>
<li>noeviction，不淘汰任何 key，而是直接返回错误信息</li>
<li>allkeys-lru，淘汰最近最少使用的 key</li>
<li>volatile-lru，在设置了过期时间的 keys 中，淘汰最近最少使用的 key</li>
<li>allkeys-random，随机淘汰一个 key</li>
<li>volatile-random，在设置了过期时间的 keys 中，随机淘汰一个 key</li>
<li>volatile-ttl，在设置了过期时间的 keys 中，淘汰剩余时间最短的 key</li>
<li>volatile-lfu，在设置了过期时间的 keys 中，淘汰访问频率最低的 key</li>
<li>allkeys-lfu，淘汰访问频率最低的 key</li>
</ul>
</li>
</ul>
<h2 id="2-2-数据持久化"><a href="#2-2-数据持久化" class="headerlink" title="2.2 数据持久化"></a>2.2 数据持久化</h2><ul>
<li>Redis 通过一些持久化方式（RDB、AOF、混合）来将数据持久化到磁盘上，从而尽可能避免数据丢失</li>
<li>RDB 是将 Redis 的内存中的数据定期保存到磁盘上，以防止数据在 Redis 进程异常退出等情况下丢失，快照文件小、恢复速度快，适合做备份和灾难恢复，但依旧可能会丢数据（最后一次快照之后的数据）</li>
<li>AOF 是将 Redis 所有的写操作追加到 AOF (Append Only File) 文件的末尾，从而记录 Redis 服务器运行期间所有的修改，当 Redis 重启时可以通过执行 AOF 文件中保存的写操作来恢复数据，可以实现更高的数据可靠性，支持更细粒度的数据恢复，适合做数据存档和备份，但文件大占用空间多，每次写操作都需要写磁盘，即写操作负载高</li>
<li>AOF 有三种数据写回策略，分别是 Always（每个写命令执行完立马同步地将日志写回到磁盘）、Everysec（每个写命令执行完先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区内容写回磁盘）、No（每个写命令执行完先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘）</li>
<li>RDB 和 AOF 混合持久化会在开头将持久化数据以 RDB 的格式写入到 AOF 文件开头，之后的数据再以 AOF 格式化追加到文件末尾，从而结合 RDB 和 AOF 的优点，但会使得 AOF 文件的可读性变差</li>
<li>持久化机制也不是完全可靠的（即便是基于 Always 的 AOF 持久化），并不能完全保证数据不会丢失</li>
</ul>
<h2 id="2-3-数据过期"><a href="#2-3-数据过期" class="headerlink" title="2.3 数据过期"></a>2.3 数据过期</h2><ul>
<li>Redis 通过设置过期时间来控制键值对的生命周期，过期策略采用定期删除和惰性删除相结合的方式</li>
<li>定期删除是指 Redis 默认每隔 100 ms 就随机抽取一些设置了过期时间的 key，将已过期的 key 删除但不会立即释放内存，而是把这些 key 标记为已过期并放入一个专门的链表中，当 Redis 的内存使用率达到一定阈值时，会这些已过期的 key 进行一次内存回收，可以确保过期的 key 能够被及时删除，但是扫描 key 会占用 CPU 资源，可能会影响 Redis 性能</li>
<li>惰性删除是指一个已经过期的 key 并不会被马上删除，而是在访问这个 key 时才会触发删除操作，可以节省 CPU 资源，但是会占用更多内存空间</li>
<li>由于 Redis 并不保证数据在过期时能被立即删除，因此基于过期消息来驱动业务并不靠谱，延迟时间可能会很长，还缺乏对这种过期消息的持久化，可能会直接丢消息，更好的方式参见 4.2 小节</li>
</ul>
<h2 id="2-4-数据结构"><a href="#2-4-数据结构" class="headerlink" title="2.4 数据结构"></a>2.4 数据结构</h2><p>Redis 提供多个数据结构，比如字符串、哈希表、列表、集合、有序集合、地理坐标、Stream 等，这些数据结构都被实现得非常高效，能够在 O(1) 的时间复杂度内完成数据读写</p>
<ul>
<li>字符串<ul>
<li>Redis 本身是通过 C 语言实现的，C 语言中的字符串以<code>\0</code>结尾，这意味着起码无法存储<code>\0</code>字符，C 语言的字符串操作都需要从头开始遍历直到找到<code>\0</code>，操作效率低</li>
<li>考虑到字符串在 Redis 中使用非常广泛，并且需要非常高效地支持任意字符的存储，Redis 并没有直接使用 C 语言中的字符数组的方式来实现字符串，而是自己实现了一个 Simple Dynamic Strings (SDS)</li>
<li>为了解决 C 语言中的字符串的问题，Redis 在字符串中增加一个表示分配给该字符数组的总长度的<code>alloc</code>字段和一个表示字符串现有长度的<code>len</code>字段，在做追加操作时如果<code>len</code>超过<code>alloc</code>则重新再申请新空间</li>
</ul>
</li>
<li>哈希表<ul>
<li>Redis 通过渐进式 rehash 实现哈希表的扩容，这种渐进式 rehash 会分多个步骤逐渐完成扩容，期间可以继续提供读写服务，不会由于一次性扩容和大量元素迁移导致线程阻塞并对性能造成影响</li>
<li>Redis 哈希表底层使用了两个全局哈希表（表1 和表 2），并维护一个初始值为 -1 的下标来记录 rehash 的下标位置，当开始向 Redis 哈希表中插入数据时，底层只使用一个哈希表（表 1），随着数据增多，底层将另一个哈希表（表 2）容量扩大一倍，并在后续有对 Redis 哈希表的增删改查操作时，就将表 1 的 rehash 下标位置的桶中的数据迁移到表 2 中，并将 rehash 下标加一自增，然后对表 2 进行相应的操作，直到表 1 中的元素全部迁移完成后互换表 1 和表 2 指针</li>
</ul>
</li>
<li>有序集合<ul>
<li>ZSet（也称为 Sorted Set）内部维护了一个有序字典，这个字典的元素中既包括了一个成员，也包括了一个分值，这种结果可以帮助用户实现记分类型的排行榜数据</li>
<li>ZSet 的实现有压缩列表 ZipList 和跳跃表 SkipList，在 Redis 5.0 中新增了一个紧凑列表 ListPack，ListPack 通过连续存储元素来节约内存空间，ListPack 就是为了代替 ZipList，在 Redis 7.0 中已经彻底不再使用 ZipList</li>
<li>SkipList 使用了跳表（带多级索引的有序链表）和字典（哈希表），每个元素按照其分值大小在跳表中进行排序，跳表的插入、删除和查找的时间复杂度都是 O(logn)，哈希表用来实现元素到分值的映射关系（元素作为键，分值作为值），哈希表的插入、删除和查找的时间复杂度都是 O(1)，可以保证比较好的性能</li>
<li>当 ZSet 的元素数据比较少时（元素数量少于 128，每个元素长度都小于 64 字节），Redis 会采用 ListPack 来存储，当 ZSet 的元素增多时，Redis 会自动将 ListPack 转换为 SkipList，以保持元素的有序性并支持范围查询，这个过程中 Redis 会遍历 ListPack 中所有元素，按照元素的分数值依次将它们插入到 SkipList 中</li>
</ul>
</li>
<li>Stream<ul>
<li>Redis Stream 是 Redis 5.0 中新增的数据结构，可以被视为一个消息队列（在 Redis 5.0 之前，可以通过 Redis 的发布订阅（pub/sub）实现消息队列，但是这种方式无法进行消息持久化，一旦出现网路断开、Redis 宕机等，消息就会被丢弃）</li>
<li>Stream 底层采用类似于日志的数据结构，每个 Stream 都是由一个或多个日志实现的，每个日志包含多个消息，每个消息都有一个唯一 ID 和一些附加字段（消息体、时间戳等），并且按照添加的顺序进行排序，可以向 Stream 中添加消息、读取消息、删除消息以及订阅消息</li>
<li>Stream 主要用于处理有序的、可追溯的消息流，提供了消息的持久化、主备复制、消息分组以及消费者分组等功能，可以让多个消费者并发地处理消息流，支持竞争式消费和共享式消费</li>
<li>基于 Stream 的消息队列一般用于实时消息传递和事件驱动的应用程序中，例如即时通讯、日志处理、实时数据更新、缓存刷新等</li>
</ul>
</li>
</ul>
<h2 id="2-5-键值对设计"><a href="#2-5-键值对设计" class="headerlink" title="2.5 键值对设计"></a>2.5 键值对设计</h2><p>在设计 Redis 的 key 和 value 时，应当以数据存储和检索效率为原则进行设计</p>
<ul>
<li>设计 key<ul>
<li>具备良好的可读性和简洁性，尽量使用短且有意义的 key（过长的 key 太占用内存空间）</li>
<li>避免在 key 中使用特殊字符，命名中尽量只包含大小写字母、数字、竖线、下划线、英文句点和英文冒号</li>
<li>使用命名空间前缀来区分不同部分的 key</li>
</ul>
</li>
<li>设计 value<ul>
<li>根据数据的特性选择合适的数据结构，从而提高操作效率</li>
<li>尽量将大数据分割为多个小 value，避免大 key，从而提高性能和降低内存使用</li>
<li>设置适当的过期时间，从而降低内存使用</li>
<li>尽量先对数据进行压缩再存储，从而降低内存使用</li>
</ul>
</li>
</ul>
<h1 id="3、问题"><a href="#3、问题" class="headerlink" title="3、问题"></a>3、问题</h1><h2 id="3-1-热-Key-问题"><a href="#3-1-热-Key-问题" class="headerlink" title="3.1 热 Key 问题"></a>3.1 热 Key 问题</h2><p>当使用 Redis 作为存储时，如果在某个时间段内，突发大量针对某一个 key 的访问，就会使得流量集中在一些极少数的物理资源上，这就是热 key 问题，针对这一问题的主要处理方式如下</p>
<ul>
<li>事前预测一些可能性热 key，在客户端、服务端或者代理层实时的统计一些可能性热 key</li>
<li>针对热 key 加分片或者加后缀来将一个热 key 拆分成多个 key，令请求尽可能分散到不同机器上</li>
<li>针对热 key 加缓存，令用户请求尽可能提前返回，减少系统交互，减少用户的访问链路长度</li>
<li>缓存多了就成为了多级缓存，注意不要使用单个缓存服务器，而是使用缓存服务器集群</li>
</ul>
<h2 id="3-2-大-Key-问题"><a href="#3-2-大-Key-问题" class="headerlink" title="3.2 大 Key 问题"></a>3.2 大 Key 问题</h2><p>大 key 是指 Redis 中存储了大量数据的 key，这个 key 对应的 value 占用空间很大，通常在字符串、列表、集合等类型出现的比较多，大 key 不仅占用内存，影响性能，还会使得多个服务节点之间的内存使用不均匀，影响 Redis 备份、迁移和恢复，关于大 key 的搜索会更加困难，大 key 数据的过期删除也比较耗时，针对大 key 问题的主要处理方式如下</p>
<ul>
<li>有选择地删除一些访问频率低的大 key，或者为大 key 设置合理的缓存 TTL</li>
<li>将大 key 拆分为多个小一些的 key，或者通过 Redis Cluster 模式将大 key 分散到不同服务节点上</li>
<li>将大 key 放在单独的数据库中，方便实现对大 key 的针对性部分迁移</li>
</ul>
<h2 id="3-3-缓存击穿"><a href="#3-3-缓存击穿" class="headerlink" title="3.3 缓存击穿"></a>3.3 缓存击穿</h2><p>缓存击穿指当某个访问频率比较高的 key 的缓存过期后大量并发请求同时访问该 key 时，就会瞬间击穿缓存服务器直接访问数据库，令数据库负载过高</p>
<ul>
<li>可以通过定时任务在 key 临近过期时去更新这个 key 的数据并重新设置过期时间</li>
<li>可以在发现缓存中的数据为 NULL 时先获取互斥锁，再去从数据库加载数据，数据加载到缓存之后再释放锁，期间其他针对该 key 的请求都被阻塞直到数据被加载缓存中</li>
</ul>
<h2 id="3-4-缓存穿透"><a href="#3-4-缓存穿透" class="headerlink" title="3.4 缓存穿透"></a>3.4 缓存穿透</h2><p>缓存穿透指服务器缓存和数据库中都没有符合条件的数据，业务系统每次都绕过缓存服务器查询下游数据库，缓存完全失去了应有的作用</p>
<ul>
<li>缓存穿透很多时候是由大量随机生成 key 的恶意请求导致的（随机生成的 key 肯定是缓存和数据库中都没有的）</li>
<li>可以通过缓存空值来直接返回 NULL，避免频繁访问数据库，但这个 NULL 值一定要设置过期时间</li>
<li>可以通过布隆过滤器来过滤那些针对一定不存在的 key 的请求，布隆过滤器是 Redis 提供的一种概率性数据结构，可以高效地检测一个元素是否存在于一个集合中，占用内存少</li>
</ul>
<h2 id="3-5-缓存雪崩"><a href="#3-5-缓存雪崩" class="headerlink" title="3.5 缓存雪崩"></a>3.5 缓存雪崩</h2><p>缓存雪崩是指大量缓存同时过期或者缓存服务宕机，所有请求都直接访问数据库，令数据库负载过高</p>
<ul>
<li>可以尽量给大量 key 设置不同的过期时间，避免都在同一时间过期，并通过定时任务定时刷新数据并重新设置过期时间</li>
<li>可以采用集群方式部署缓存，避免单点缓存故障</li>
</ul>
<h2 id="3-6-缓存和数据库不一致"><a href="#3-6-缓存和数据库不一致" class="headerlink" title="3.6 缓存和数据库不一致"></a>3.6 缓存和数据库不一致</h2><p>数据库更新操作和缓存更新操作这两步操作之间是无法确保没有其他线程进行操作的（即操作原子性无法保证），一旦多线程并发更新数据库和缓存，就会导致缓存和数据库数据不一致。</p>
<p>可以通过延迟双删来更新数据并保证缓存和数据库之间的数据一致性</p>
<ul>
<li>延迟双删指先删除缓存，再更新数据库，最后再删除缓存，优先考虑删除缓存而不是更新缓存，这样处理更加简单且不容易出错</li>
<li>更新数据库之间如果没有删除缓存，那么如果在数据库更新之后的缓存删除失败了，后续通过缓存拿到的数据就都是错误的，所以先确保缓存已经删除了，再去更新数据库</li>
<li>更新数据库之后如果没有删除缓存，那么如果在数据库更新期间存在其他请求通过读操作顺便地将更新之前的数据再加载回缓存，后续通过缓存拿到的数据依旧都是错误的，所以在数据库更新之后再重新删一次缓存，确保缓存中没有脏数据</li>
<li>更新数据库之后的缓存删除也可以改成借助数据库 BinLog，订阅到数据库变更消息之后异步地删除缓存</li>
</ul>
<h2 id="3-7-缓存集群之间不一致"><a href="#3-7-缓存集群之间不一致" class="headerlink" title="3.7 缓存集群之间不一致"></a>3.7 缓存集群之间不一致</h2><p>即便使用集群模式，依旧可能出现主节点在数据还未同步到其他从节点时发生故障，后续新选出的主节点并不具备和原主节点一致的数据</p>
<ul>
<li>数据丢失<ul>
<li>数据丢失是数据不一致的一种情况，比如基于 Redis 集群的分布式锁就可能无法顺利在节点间同步已经被获取的锁，进而发生锁丢失</li>
<li>红锁（RedLock）是 Redis 提出的一个多节点分布式锁算法，旨在解决单节点 Redis 分布式锁可能存在的单点故障和锁丢失问题</li>
<li>RedLock 在进行加锁操作时，RedLock 会向每个 Redis 节点发生相同的命令请求，每个节点都会去竞争锁，如果在大多数节点上成功获取了锁，那么就认为加锁成功，从而避免主节点故障又未能及时将锁同步到其他节点的情况</li>
<li>RedLock 并没有完全解决 Redis 分布式锁的问题，在脑裂的情况下可能会出现多个客户端同时持有锁</li>
</ul>
</li>
<li>脑裂<ul>
<li>脑裂是网络分区故障的一种具体表现，也是数据不一致的一种导致原因，是指集群中的出现多个节点都认为自己是主节点，进而导致数据不一致、数据丢失、重复写入等问题，一般发生在网络中断或主节点出现问题的时候</li>
<li>网络中断和主节点故障都是可能导致脑裂的原因，网络故障或网络分区会导致集群不同子集之间的网络通信中断，进而导致一部分节点被划分到了单独的一个网络中，这部分节点找不到主节点就会重新选出一个新的主节点，集群中就出现了多个主节点；主节点出现问题后又快速恢复了，这期间有部分从节点又重现选出了新的主节点，集群中就出现了多个主节点</li>
<li>Redis 可以通过配置来尽量规避脑裂问题，但无法彻底杜绝</li>
</ul>
</li>
<li>时间漂移<ul>
<li>时间漂移也是数据不一致的一种导致原因，是指不同的机器之间的时间可能存在微小的不一致，进而导致分布式系统的数据不一致（比如锁失效时间不一致，然后有的 Redis 已经解锁并使得新的客户端能够获取到的锁）</li>
<li>RedLock 可以使用 NTP 等工具来同步不同机器之间的事件，尽量避免时间漂移</li>
</ul>
</li>
</ul>
<h2 id="3-8-使用注意"><a href="#3-8-使用注意" class="headerlink" title="3.8 使用注意"></a>3.8 使用注意</h2><ul>
<li>避免使用 KEYS 命令获取所有 key，该命令会遍历所有 key，可能会长时间阻塞 Redis 主线程</li>
<li>避免使用 FLUSHALL 或 FLUSHDB 命令清空 Redis，这会清空所有数据库中的所有数据，不仅仅是当前数据库</li>
<li>对于写操作频繁的数据，可以使用哈希表结构（可以做部分更新，减少网络传输数据量），并考虑使用 Redis 持久化机制进行数据持久化，以保证数据可靠性</li>
<li>避免在 Lua 脚本中使用死循环，这会导致 Redis 主线程被无限阻塞</li>
<li>避免在 Redis 实例上进行复杂的计算逻辑，这会导致 Redis 主线程被阻塞</li>
<li>对于高并发场景，可以使用 Redis 的分布式锁机制</li>
<li>对于高可用场景，可以使用 Redis Cluster 进行搭建</li>
</ul>
<h1 id="4、应用"><a href="#4、应用" class="headerlink" title="4、应用"></a>4、应用</h1><p>Redis 的主要应用有缓存、消息队列、延迟消息队列、分布式锁、分布式限流、分布式 Session、排行榜、地理位置应用，布隆过滤器等。</p>
<h2 id="4-1-消息队列"><a href="#4-1-消息队列" class="headerlink" title="4.1 消息队列"></a>4.1 消息队列</h2><ul>
<li>Redis 的发布订阅（pub/sub）机制<ul>
<li>无法进行消息持久化，一旦出现网路断开、Redis 宕机等，消息就会被丢弃，在高频次请求下性能表现较差</li>
</ul>
</li>
<li>Redis Stream<ul>
<li>Redis Stream 是 Redis 5.0 中新增的数据结构，可以被视为一个消息队列</li>
<li>Stream 底层采用类似于日志的数据结构，每个 Stream 都是由一个或多个日志实现的，每个日志包含多个消息，每个消息都有一个唯一 ID 和一些附加字段（消息体、时间戳等），并且按照添加的顺序进行排序，可以向 Stream 中添加消息、读取消息、删除消息以及订阅消息</li>
<li>Stream 主要用于处理有序的、可追溯的消息流，提供了消息的持久化、主备复制、消息分组以及消费者分组等功能，可以让多个消费者并发地处理消息流，支持竞争式消费和共享式消费</li>
<li>基于 Stream 的消息队列一般用于实时消息传递和事件驱动的应用程序中，例如即时通讯、日志处理、实时数据更新、缓存刷新等</li>
</ul>
</li>
</ul>
<h2 id="4-2-延迟消息队列"><a href="#4-2-延迟消息队列" class="headerlink" title="4.2 延迟消息队列"></a>4.2 延迟消息队列</h2><ul>
<li>数据过期监听机制<ul>
<li>由于 Redis 并不保证数据在过期时能被立即删除，更不保证过期消息能够被立即发出，因此基于过期消息来驱动业务并不靠谱，延迟时间可能会很长，还缺乏对这种过期消息的持久化，可能会直接丢消息</li>
</ul>
</li>
<li>有序集合 ZSet<ul>
<li>将超时时间设置为元素的分值 score，Redis 会对 ZSet 按照 score 进行排序，然后再开启 Redis 扫描任务获取当前时间超过 score 的元素从而驱动相关业务操作</li>
<li>基于 ZSet 的延迟消息队列可以借助 Redis 的持久化、高可用机制来避免数据丢失，但是需要基于 ZSet 来自行编写代码，且在高并发场景下可能会出现重复消息</li>
</ul>
</li>
<li>Redission<ul>
<li>Redisson 是一个基于 Redis 的 Java 客户端框架，提供了分布式延迟队列 RDelayedQueue（底层就是 ZSet），允许以指定的延迟时长将元素放入队列中并起一个延时任务，任务到期时会将元素取出来返回给客户端使用</li>
<li>Redisson 的 RDelayedQueue 可以解决 ZSet 中的消息重复问题，使用简单，稳定性和性能都比较好</li>
</ul>
</li>
</ul>
<h2 id="4-3-分布式锁"><a href="#4-3-分布式锁" class="headerlink" title="4.3 分布式锁"></a>4.3 分布式锁</h2><ul>
<li>SETNX<ul>
<li>多个 Redis 客户端同时通过 SETNX 命令尝试获取锁，Redis 的单线程特性会确保只有一个客户端可以获取锁成功</li>
<li>获取到锁的客户端宕机重启后无法释放锁，因此请求锁的同时也应当设置一个过期时间来确保锁一定会被释放，避免死锁，但是过长的过期时间会影响分布式锁的并发性能</li>
<li>如果需要支持可重入，则需要在获取锁时通过一个全局唯一标识来识别特定线程，根据这个标识来判断尝试获取锁的线程是否已经持有了锁，并额外维护一个重入次数的字段</li>
<li>这种方式实现的分布式锁使用简单，便于理解，性能较高，但锁无法续期，可能会出现死锁（如果没有设置过期时间的话）</li>
</ul>
</li>
<li>Redisson<ul>
<li>Redisson 提供了包括分布式锁功能，支持分布式锁的可重入、公平锁、联锁、读写锁、阻塞或非阻塞以及 RedLock 等</li>
<li>Redisson 引入看门狗机制来在 Redisson 实例运行期间不断延长锁的有效期直到释放锁（这个后台任务是基于 JVM 运行的），如果在加锁时指定了超时时间则不会续期，如果 Redis 线程中断、服务宕机下线等则会停止续期</li>
</ul>
</li>
</ul>
<h2 id="4-4-分布式限流"><a href="#4-4-分布式限流" class="headerlink" title="4.4 分布式限流"></a>4.4 分布式限流</h2><p>滑动窗口是一种流量控制策略，窗口会随着时间推移而不断滑动，在窗口内允许的操作数量是固定的，用于控制一定时间内允许执行的操作数量或请求频次，这种平滑地控制流量而不是简单地设置固定的请求次数或速率，可以使得系统更加灵活地应对突发流量，不会为固定速率的限制而浪费资源或降低系统性能。</p>
<p>Redis 可以通过 ZSet 在每一次接收到请求时记录下请求的时间戳和请求的数据，但只记录特定时间窗口内的请求，丢弃窗口之外的请求。</p>
<h2 id="4-5-布隆过滤器"><a href="#4-5-布隆过滤器" class="headerlink" title="4.5 布隆过滤器"></a>4.5 布隆过滤器</h2><p>布隆过滤器是一种快速检索元素是否可能存在于一个集合中的数据结构，可以在空间和时间上实现比较高的效率</p>
<ul>
<li>基本原理是利用多个哈希函数将一个元素映射成多个位并将这些位设为 1，当查询一个元素是否存在时，如果该元素所对应的比特位均为 1，则该元素可能存在于集合中，否则则可能不存在</li>
<li>由于哈希冲突无法确定判断一定存在，只能判断可能存在和一定不存在，可以通过降低哈希冲突以及引入更多的哈希算法来将降低误判的概率。此外，在删除元素时可能会影响到其他元素</li>
</ul>
<p>布隆过滤器的典型应该场景有</p>
<ul>
<li>网页爬虫程序使用布隆过滤器来过滤已经爬取过的网页，避免重复爬取和资源浪费</li>
<li>缓存系统使用布隆过滤器判断一个查询是否可能存在于缓存中，从而提高查询效率，也经常用来解决缓存穿透的问题</li>
<li>黑名单过滤器使用布隆过滤器来判断用户是否存在于黑名单中，从而阻止恶意请求</li>
</ul>
<p>Java 可以使用 Google Guava 库、Apache Commons 库以及 Redis 来实现布隆过滤器</p>
<h1 id="5、补充"><a href="#5、补充" class="headerlink" title="5、补充"></a>5、补充</h1><h2 id="5-1-不同缓存类型"><a href="#5-1-不同缓存类型" class="headerlink" title="5.1 不同缓存类型"></a>5.1 不同缓存类型</h2><ul>
<li><p>本地缓存</p>
<ul>
<li>将数据存储在单个应用程序的内存中，访问速度快、易于使用和管理，但不能跨多个节点共享缓存，存在一致性问题使其无法用于集群环境，适合单个应用程序的性能优化</li>
<li>为了提升缓存的效率，本地缓存通常采用 Key-Value 结构进行数据存储，本地缓存作为一个全局可访问的变量，需要考虑线程安全问题，本地缓存会占用 JVM 堆内存，需要考虑存储空间问题、过期时间和清除策略</li>
<li>推荐使用的比较成熟的本地缓存框架是 Caffeine，Caffeine 是 Spring 5 中默认支持的本地缓存，采用 W-TinyLFU 缓存失效算法，性能良好，支持异步 Cache，很多工作都是交由线程池去做的，支持写入外部资源</li>
</ul>
</li>
<li><p>分布式缓存</p>
<ul>
<li>将数据存储在多个节点的内存中，这些节点可以在不同的服务器，甚至是不同的地理位置上，可以支持多个应用程序共享数据，提高系统的可伸缩性和可用性，管理和维护成本较高，需要考虑数据一致性和故障恢复等问题</li>
<li>Redis 就是一个分布式缓存框架</li>
</ul>
</li>
<li><p>多级缓存</p>
<ul>
<li>多级缓存是比较常见的一种性能优化手段，一般就是本地缓存加上分布式缓存，优先查询本地缓存，如果本地缓存中查不到，再查询分布式缓存并将其保存到本地缓存，多级缓存的问题在于缓存数据一致性</li>
<li>一般是将变化不频繁且能够接受一定程度的不一致的数据考虑放到本地缓存中（变化频繁的数据会带来严重的一致性问题，和本地缓存的思想是相悖的），基于业务能够接受的不一致时长来设置本地缓存的失效时长</li>
</ul>
</li>
<li><p>近端缓存</p>
<ul>
<li>通常是指位于网络边缘、距离用户位置更近的缓存，用于在网络上尽可能快地向用户提高内容，减少用户请求的响应时间和带宽占用，典型例子是 CDN，详细参见 <a href="../../../../2023/11/06/computer-networking/">Computer Networking</a> 的 2.5 小节</li>
<li>由于应用服务器比分布式缓存距离用户也更近一些，因此和应用服务器部署在一起的本地缓存也可以称为近端缓存</li>
</ul>
</li>
</ul>
<h2 id="5-2-缓存失效算法"><a href="#5-2-缓存失效算法" class="headerlink" title="5.2 缓存失效算法"></a>5.2 缓存失效算法</h2><p>当缓存中存储地对象过多时，需要通过缓存失效算法选择出需要被淘汰的对象，常见的缓存失效算法如下</p>
<ul>
<li>FIFO<ul>
<li>选择最先进行缓存的数据，使用队列，淘汰队头</li>
</ul>
</li>
<li>LRU<ul>
<li>选择最久没有被访问的数据，可以使用链表，每次访问缓存数据后将其移动到链表头部，淘汰链表尾部</li>
<li>在 Redis、Memcached 中有被广泛使用</li>
</ul>
</li>
<li>LFU<ul>
<li>选择最小频率被访问的数据，可以对每个缓存数据块进行引用计数，具有相同计数的数据块则按照时间排序，淘汰排序后末尾的数据块</li>
<li>通常能够实现最佳的缓存命中率，但需要给每个缓存数据块维护频率信息，每次访问缓存都需要更新，需要较大的空间，时间性能也较差</li>
<li>无法很好的清除那种早期访问频率很高，后期不再访问的数据，也容易淘汰刚刚加入缓存的数据块</li>
</ul>
</li>
<li>W-TinyLFU<ul>
<li>是基于窗口（W 就是 Window）的近似虽少使用算法，根据数据的访问模式动态地调整缓存中数据的淘汰策略，综合了 LRU 和 LFU 的长处，高命中率、低内存占用，是一种高效的缓存淘汰算法，主要用于处理大规模缓存系统中的淘汰问题</li>
<li>使用 LRU 作为窗口缓存，让数据块能够有机会在窗口缓存中积累它的频率，避免淘汰刚刚加入缓存的低频数据，使用 SLRU 作为主缓存，数据块被挤出窗口缓存时，会在过滤器和主缓存中最容易被淘汰的数据块进行竞争，如果频率大于主缓存中最低频的数据块，才能进入主缓存</li>
</ul>
</li>
</ul>
</section>
    <!-- Tags START -->
    
    <!-- Tags END -->
    <!-- NAV START -->
    
  <div class="nav-container">
    <!-- reverse left and right to put prev and next in a more logic postition -->
    
      <a class="nav-left" href="/2024/02/06/distributed-system/">
        <span class="nav-arrow">← </span>
        
          Distributed System
        
      </a>
    
    
      <a class="nav-right" href="/2024/02/18/week-75/">
        
          2024.2.5 - 2024.2.9
        
        <span class="nav-arrow"> →</span>
      </a>
    
  </div>

    <!-- NAV END -->
    <!-- 打赏 START -->
    
    <!-- 打赏 END -->
    <!-- 二维码 START -->
    
    <!-- 二维码 END -->
    
      <!-- Utterances START -->
      <div id="utterances"></div>
      <script src="https://utteranc.es/client.js"
        repo=""
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async></script>    
      <!-- Utterances END -->
    
  </article>
  <!-- Article END -->
  <!-- Catalog START -->
  
    <aside class="catalog-container">
  <div class="toc-main">
  
      
          <strong class="toc-title">OUTLINE</strong>
          <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#1%E3%80%81%E6%A8%A1%E5%BC%8F"><span class="toc-nav-text">1、模式</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#1-1-%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F"><span class="toc-nav-text">1.1 集群模式</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#1-2-%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE"><span class="toc-nav-text">1.2 通信协议</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#1-3-%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B"><span class="toc-nav-text">1.3 并发模型</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#1-4-%E4%BA%8B%E5%8A%A1%E6%9C%BA%E5%88%B6"><span class="toc-nav-text">1.4 事务机制</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#1-5-%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C"><span class="toc-nav-text">1.5 原子操作</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#1-6-Pipeline-%E6%9C%BA%E5%88%B6"><span class="toc-nav-text">1.6 Pipeline 机制</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#2%E3%80%81%E5%AD%98%E5%82%A8"><span class="toc-nav-text">2、存储</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-1-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="toc-nav-text">2.1 内存管理</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-2-%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-nav-text">2.2 数据持久化</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-3-%E6%95%B0%E6%8D%AE%E8%BF%87%E6%9C%9F"><span class="toc-nav-text">2.3 数据过期</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-4-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-nav-text">2.4 数据结构</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-5-%E9%94%AE%E5%80%BC%E5%AF%B9%E8%AE%BE%E8%AE%A1"><span class="toc-nav-text">2.5 键值对设计</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#3%E3%80%81%E9%97%AE%E9%A2%98"><span class="toc-nav-text">3、问题</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#3-1-%E7%83%AD-Key-%E9%97%AE%E9%A2%98"><span class="toc-nav-text">3.1 热 Key 问题</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#3-2-%E5%A4%A7-Key-%E9%97%AE%E9%A2%98"><span class="toc-nav-text">3.2 大 Key 问题</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#3-3-%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF"><span class="toc-nav-text">3.3 缓存击穿</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#3-4-%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F"><span class="toc-nav-text">3.4 缓存穿透</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#3-5-%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9"><span class="toc-nav-text">3.5 缓存雪崩</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#3-6-%E7%BC%93%E5%AD%98%E5%92%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8D%E4%B8%80%E8%87%B4"><span class="toc-nav-text">3.6 缓存和数据库不一致</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#3-7-%E7%BC%93%E5%AD%98%E9%9B%86%E7%BE%A4%E4%B9%8B%E9%97%B4%E4%B8%8D%E4%B8%80%E8%87%B4"><span class="toc-nav-text">3.7 缓存集群之间不一致</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#3-8-%E4%BD%BF%E7%94%A8%E6%B3%A8%E6%84%8F"><span class="toc-nav-text">3.8 使用注意</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#4%E3%80%81%E5%BA%94%E7%94%A8"><span class="toc-nav-text">4、应用</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#4-1-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97"><span class="toc-nav-text">4.1 消息队列</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#4-2-%E5%BB%B6%E8%BF%9F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97"><span class="toc-nav-text">4.2 延迟消息队列</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#4-3-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-nav-text">4.3 分布式锁</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#4-4-%E5%88%86%E5%B8%83%E5%BC%8F%E9%99%90%E6%B5%81"><span class="toc-nav-text">4.4 分布式限流</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#4-5-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8"><span class="toc-nav-text">4.5 布隆过滤器</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#5%E3%80%81%E8%A1%A5%E5%85%85"><span class="toc-nav-text">5、补充</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#5-1-%E4%B8%8D%E5%90%8C%E7%BC%93%E5%AD%98%E7%B1%BB%E5%9E%8B"><span class="toc-nav-text">5.1 不同缓存类型</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#5-2-%E7%BC%93%E5%AD%98%E5%A4%B1%E6%95%88%E7%AE%97%E6%B3%95"><span class="toc-nav-text">5.2 缓存失效算法</span></a></li></ol></li></ol>
      
  
  </div>
</aside>
  
  <!-- Catalog END -->
</main>

<script>
  (function () {
    var url = 'http://example.com/2024/02/18/redis/';
    var banner = ''
    if (banner !== '' && banner !== 'undefined' && banner !== 'null') {
      $('#article-banner').css({
        'background-image': 'url(' + banner + ')'
      })
    } else {
      $('#article-banner').geopattern(url)
    }
    $('.header').removeClass('fixed-header')

    // error image
    $(".markdown-content img").on('error', function() {
      $(this).attr('src', '/css/images/error_icon.png')
      $(this).css({
        'cursor': 'default'
      })
    })

    // zoom image
    $(".markdown-content img").on('click', function() {
      var src = $(this).attr('src')
      if (src !== '/css/images/error_icon.png') {
        var imageW = $(this).width()
        var imageH = $(this).height()

        var zoom = ($(window).width() * 0.95 / imageW).toFixed(2)
        zoom = zoom < 1 ? 1 : zoom
        zoom = zoom > 2 ? 2 : zoom
        var transY = (($(window).height() - imageH) / 2).toFixed(2)

        $('body').append('<div class="image-view-wrap"><div class="image-view-inner"><img src="'+ src +'" /></div></div>')
        $('.image-view-wrap').addClass('wrap-active')
        $('.image-view-wrap img').css({
          'width': `${imageW}`,
          'transform': `translate3d(0, ${transY}px, 0) scale3d(${zoom}, ${zoom}, 1)`
        })
        $('html').css('overflow', 'hidden')

        $('.image-view-wrap').on('click', function() {
          $(this).remove()
          $('html').attr('style', '')
        })
      }
    })
  })();
</script>







    <div class="scroll-top">
  <span class="arrow-icon"></span>
</div>
    <footer class="app-footer">
  <p class="copyright">
    &copy; 2024 | Proudly powered by <a href="https://hexo.io" target="_blank">Hexo</a>
    <br>
    Theme by <a target="_blank" rel="noopener" href="https://github.com/yanm1ng">yanm1ng</a>
    
  </p>
</footer>

<script>
  function async(u, c) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }
</script>
<script>
  async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
    FastClick.attach(document.body);
  })
</script>

<script>
  var hasLine = 'true';
  async("//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js", function(){
    $('figure pre').each(function(i, block) {
      var figure = $(this).parents('figure');
      if (hasLine === 'false') {
        figure.find('.gutter').hide();
      }
      hljs.configure({useBR: true});
      var lang = figure.attr('class').split(' ')[1] || 'code';
      var codeHtml = $(this).html();
      var codeTag = document.createElement('code');
      codeTag.className = lang;
      codeTag.innerHTML = codeHtml;
      $(this).attr('class', '').empty().html(codeTag);
      figure.attr('data-lang', lang.toUpperCase());
      hljs.highlightBlock(block);
    });
  })
</script>
<!-- Baidu Tongji -->


<script src="/js/script.js"></script>


  </body>
</html>