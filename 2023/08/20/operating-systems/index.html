<!DOCTYPE html>
<html>
  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <meta name="description" content="要有一个从输入到输出的过程">
  <meta name="keyword" content="hexo-theme, vuejs">
  
    <link rel="shortcut icon" href="/css/images/logo.png">
  
  <title>
    
      Operating Systems | CQ&#39;s Blog
    
  </title>
  <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/tomorrow.min.css" rel="stylesheet">
  
<link rel="stylesheet" href="/css/style.css">

  
  <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/geopattern/1.2.3/js/geopattern.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.js"></script>
  
  
  
  
    <!-- MathJax support START -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- MathJax support END -->
  


  
  
    
<script src="/js/local-search.js"></script>


<meta name="generator" content="Hexo 5.4.2"></head>
<div class="wechat-share">
  <img src="/css/images/logo.png" />
</div>
  <body>
    <header class="header fixed-header">
  <div class="header-container">
    <a class="home-link" href="/">
      <div class="logo"></div>
      <span>CQ's Blog</span>
    </a>
    <ul class="right-list">
      
        <li class="list-item">
          
            <a href="/" class="item-link">Home</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/" class="item-link">Categories</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/records" class="item-link">Records</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/scratches/" class="item-link">Scratches</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/archives/" class="item-link">Archives</a>
          
        </li>
      
      
        <li class="menu-item menu-item-search right-list">
    <a role="button" class="popup-trigger">
        <i class="fa fa-search fa-fw"></i>
    </a>
</li>
      
    </ul>
    <div class="menu">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </div>
    <div class="menu-mask">
      <ul class="menu-list">
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">Home</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">Categories</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/records" class="menu-link">Records</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/scratches/" class="menu-link">Scratches</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/archives/" class="menu-link">Archives</a>
            
          </li>
        
      </ul>
    </div>
    
      <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
            <span class="search-icon">
                <i class="fa fa-search"></i>
            </span>
            <div class="search-input-container">
                <input autocomplete="off" autocapitalize="off"
                    placeholder="Please enter your keyword(s) to search." spellcheck="false"
                    type="search" class="search-input">
            </div>
            <span class="popup-btn-close">
                <i class="fa fa-times-circle"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>
    
  </div>
</header>

    <div id="article-banner">
  <h2>Operating Systems</h2>
  <!--<p class="post-date">2023-08-20</p>
  <div class="arrow-down">
    <a href="javascript:;"></a>
  </div>-->
</div>
<main class="app-body flex-box">
  <!-- Article START -->
  <article class="post-article">
    <section class="markdown-content"><h1 id="1、引言"><a href="#1、引言" class="headerlink" title="1、引言"></a>1、引言</h1><p><strong>程序</strong>最初以某个可执行格式驻留在磁盘上，是存在磁盘上面的一些指令和静态数据。<strong>程序运行之前</strong>首先需要操作系统从磁盘上读取这些字节，将代码和所有静态数据/初始化变量加载到内存中，接着为程序的运行时栈分配一些内存（也可能为堆分配一些内存，堆可能会随着程序运行变大），并执行一些与 I/O 相关的初始化任务，最后启动程序，在入口（<code>main()</code>）处令程序开始运行。<strong>程序运行</strong>其实意味着执行指令，执行指令意味着 CPU 从内存中获取一条指令，对这条指令进行解码，然后执行它，然后执行下一条指令，直到程序运行完成。</p>
<p>操作系统令程序运行起来，并将这种运行中的程序及其访问的系统的部分概括抽象为<strong>进程</strong>，操作系统创建了第一个进程（称为 init 进程）来启动系统中所有其他进程。<strong>程序启动时</strong>操作系统会在虚拟内存中给新进程分配一块专有区域来存储该进程用到的数据和代码，并将 CPU 的控制权转移到新创建的进程中，进程的机器状态指进程可以读取或更新的内容（由内存、寄存器以及持久存储设备组成），进程可以访问的内存是该进程的地址空间。</p>
<ul>
<li>进程可以处于以下这五种状态<ul>
<li>初始（initial），进程在创建时处于状态</li>
<li>就绪（ready），进程已准备好运行，但未获得 CPU 时间片</li>
<li>运行（running），进程获得 CPU 时间片，正在执行指令</li>
<li>阻塞（blocked），进程执行了某种操作，但需要等待操作完成，比如硬盘 I/O</li>
<li>最终/僵尸（final），进程已退出但尚未清理</li>
</ul>
</li>
<li>现代操作系统提供以下进程 API<ul>
<li>创建：创建新进程，运行指定的程序</li>
<li>销毁：很多进程会在运行完成后自行退出，但是对于失控的进程，用户可以强制销毁</li>
<li>等待：等待进程停止运行</li>
<li>其他控制：比如暂停正在运行的进程，恢复暂停的进程等</li>
<li>状态：获得有关进程的状态信息</li>
</ul>
</li>
<li>常见的进程间通信方式如下<ul>
<li>管道，是一种半双工的通信方式，允许一个进程写入数据到管道，另一个进程从管道中读取数据，一般用于父子进程间的通信</li>
<li>命名管道，允许不相关的进程（不具备父子关系的进程）通过给定名称的命名管道来进行通信</li>
<li>消息队列，是一种异步通信方式，一般用于分布式系统</li>
<li>共享内存，多个进程可以同一块物理内存映射到各自的地址空间中，实现共享内存</li>
<li>信号量，是一种用于进程同步和互斥的通信方式，进程可以通过信号量对资源进行加锁和解锁</li>
<li>套接字，是一种用于不同主机的进程的网络通信方式，也可以用于同一主机的不同本地进程间的通信</li>
<li>文件映射，将磁盘中的某个文件同时映射到多个进程的地址空间中，实现共享数据</li>
</ul>
</li>
</ul>
<p>操作系统就是一类通过虚拟化、并发、持久性来让多程序运行变得简单高效的软件，建立抽象，最小化开销，进程彼此隔离，不间断可靠运行是操作系统的主要设计目标。</p>
<ul>
<li>虚拟化指操作系统将<strong>物理资源（处理器、内存和磁盘）</strong>转换为更通用、更强大更易于使用的虚拟形式（因此有时也将操作系统称为资源管理器或者虚拟机），为应用程序提供了一个关于程序运行、内存分配以及文件访问的标准库</li>
<li>并发指操作系统同时运行多个进程，或者在进程当中又同时运行多个线程（并发问题并不局限于操作系统本身）</li>
<li>持久性指数据被永久地存储下来，内存中的数据并非持久性的，操作系统提供一种通过系统调用来访问硬件设备的标准和简单的方法（因此操作系统有时被视为标准库），将数据持久到磁盘等硬件中，操作系统中管理磁盘的软件通常称为文件系统。</li>
</ul>
<h1 id="2、虚拟化-CPU"><a href="#2、虚拟化-CPU" class="headerlink" title="2、虚拟化 CPU"></a>2、虚拟化 CPU</h1><p>一个正常的系统可能会有上百个进程在同时运行，操作系统将有限个 CPU 虚拟化为看似无限数量的 CPU，令一个进程只运行一个时间片，从而让多个程序看似同时运行，这就是基于时分共享的<strong>虚拟化 CPU</strong>，其开销在于性能损失，单个进程的运行会变慢。</p>
<p>注：GPU（图像处理单元）和 CPU（中央处理单元）是计算机中两种不同类型的处理器，在设计和功能上有很大的区别。CPU 旨在执行各种通用任务，具有较少的核心，但每个核心非常强大且灵活；GPU 最初是为图像渲染和图像处理而设计的，具有大量的小核心，适合并行处理，这些核心可以同时处理大量相似的重复性任务，这种任务类型的表现会比 CPU 更加高效。</p>
<h2 id="2-1-CPU-控制权"><a href="#2-1-CPU-控制权" class="headerlink" title="2.1 CPU 控制权"></a>2.1 CPU 控制权</h2><p>内核是操作系统的核心，负责管理和控制计算机硬件资源，提供各种系统服务，操作系统将应用程序和操作系统内核进行了隔离，并通过不同的特权级别（用户模式和内核模式）以及系统调用协调用户进程和内核，操作系统内核工作在内核态特权模式下，具有最高权限，可以访问所有的硬件资源和底层系统资源，用户进程工作在用户模式下，只能通过系统调用来进行用户态和内核态之间的切换，从而间接访问被授权的资源，这使得进程能够执行 I/O 和其他一些受限制的操作，但又不能让进程完全控制系统。</p>
<p>当多进程以协作方式运行时，操作系统假定进程会友好运行，并不会主动打断进程，那么只有当进程主动发起系统调用或者重启时，进程才会被中断，如果进程通过系统调用来试图访问非法内存或执行非法指令，操作系统才会终止进程。当多进程以非协作方式运行时，预先设置的时钟会定时中断当前正在运行的进程，此时该进程的用户寄存器由<strong>硬件隐式保存</strong>，使用该进程的内存栈，接着操作系统获得 CPU 控制权，非协作模式下的时钟中断可以防止协作模式下的进程死循环。</p>
<p>一旦操作系统获得 CPU 控制权，就必须通过调度程序（scheduler）决定是继续运行当前正在运行的进程，还是切换到另一个进程，如果是后者，则需进行上下文切换。</p>
<p>上下文切换意味着操作系统需要为当前正在执行的进程保存一些值（<strong>软件显式保存</strong>），并为即将执行的进程恢复一些值（这些值具体指通用寄存器，程序计数器，内核栈指针，并且都保存在内存中而不是磁盘中，从而令切换效率更高），内核通过调用被中断进程的上下文，进入用于上下文切换的底层汇编代码，并返回即将执行的进程的上下文，最后操作系统将 CPU 控制权转移给即将执行的进程，此时上下文切换完成。</p>
<h2 id="2-2-多进程调度"><a href="#2-2-多进程调度" class="headerlink" title="2.2 多进程调度"></a>2.2 多进程调度</h2><p>任务在 I/O 期间并不会使用 CPU，调度程序显然要在某个任务发起 I/O 请求时做出决定，在 CPU 上运行另一个 CPU 密集性任务，从而更好地利用 CPU，即多进程并发运行时，操作系统需要某种调度策略来在中断时决定应当运行哪个进程，并进行上下文切换。</p>
<p>进程的工作负载（任务完成时间）和比较不同调度策略所使用的指标（周转时间和响应时间）是构建调度策略的关键部分。周转时间指任务到达至任务完成之间的时间，包含了任务等待执行和任务真正执行的时间，响应时间指任务到达至任务首次开始执行的时间，即任务初次等待执行的时间。</p>
<p>1）先进先出/先到先服务（FIFO/FCFS），简单且易于实现，但平均周转时间和响应时间都较长（尤其是在完成时间较长的任务先到达时），总体性能不佳。</p>
<p>2）短任务优先（SJF）是一种非抢占式的调度策略，能保证对同时到达的任务，将完成时间较短的任务先执行，平均周转时间较短，平均响应时间较长，而当完成时间较长的任务先到达时，平均周转时间和响应时间都较长，总体性能依旧不佳。</p>
<p>3）最短完成时间优先/抢占式最短作业优先（STCF/PSJF）是添加了抢占机制的 SJF，每当新任务进入系统，会确定剩余工作和新工作中的剩余时间最少的任务来优先执行，平均周转时间达到理论最短，平均响应时间依旧较长（尤其是在完成时间较长优先级较低的任务先到达时）。</p>
<p>4）轮转（RR）在一个时间切片（又称调度量子，其长度必须是时钟中断周期的倍数）内运行一个任务，然后切换到运行队列中的下一个任务（而不是运行一个任务直到结束），直到所有任务都完成，平均响应时间较短，但拥有几乎最长的平均周转时间。时间切片越短，平均响应时间就越小，但频繁的上下文切换将影响整体性能，因此时间切片的长度需要在系统响应时间和上下文切换成本之间进行权衡。</p>
<p>5）多级反馈队列（MLFQ）有多个互相独立的队列，每个队列有不同的优先级，从而利用 STCF 优化平均周转时间或者利用 RR 优化平均响应时间，并利用任务最近的运行行为历史预测任务的未来执行情况，从而动态调整任务应该归属于哪个优先级队列。</p>
<ul>
<li>总是优先执行优先级较高的队列中的任务</li>
<li>同一个队列中的任务具备同样的优先级，轮流执行</li>
<li>任务刚进入系统时，加入优先级最高的上层队列</li>
<li>任务在用完其在某一层队列中的时间配额之前（假定为交互型任务）优先级不变，一旦时间配额用完（假定为密集型任务），降低其优先级，移入下一级队列</li>
<li>经过一段时间 S，就将所有任务都重新加入最高优先级队列（避免优先级低的任务长时间饥饿）</li>
</ul>
<p>MLFQ 的各项参数并没有显而易见的取值，需要利用对任务工作负载的经验对调度程序进行调优，例如不同队列设置可变的时间切片长度，高优先级队列通常有较短的时间切片，低优先级队列通常有较长的时间切片。</p>
<p>6）比例份额/公平份额按照一定概率随机选择应该运行哪个任务，越是应该频繁运行的进程，越是应该拥有更高的概率被选中。这种随机决策的方式可以避免奇怪的边角最差情况，且由于不需要记录太多状态，非常轻量，计算便捷，做出决策的速度很快，但是不能很好地适应 I/O，且难以确定各个任务应该分配设置多大的份额/选中概率。</p>
<h2 id="2-3-多核-CPU-调度"><a href="#2-3-多核-CPU-调度" class="headerlink" title="2.3 多核 CPU 调度"></a>2.3 多核 CPU 调度</h2><p>上文所述调度策略均是在单核 CPU 的前提下提出的，而针对多核 CPU，则存在一些新的问题需要在调度策略中加以考虑。</p>
<p>1）缓存一致性问题</p>
<p>CPU 的硬件缓存是很小但很快的存储设备，通常拥有内存中最热的数据的备份，相比之下，内存很大且拥有所有的数据，但访问数据较慢。由于大多数程序都存在时间局部性和空间局部性，硬件系统可以根据局部性来很好地预测那些数据可以放入缓存中（时间局部性指一个数据被访问后，很有可能会在不久的将来被再次访问；空间局部性指一个数据被访问后，很有可能会紧接着访问它周围的数据）。</p>
<p>通过将频繁访问的数据放在缓存中，系统似乎拥有又大又快的内存。然而，当系统具备多核 CPU 时，每个 CPU 都具备自己的缓存，但这些 CPU 共享同一个内存，那么当更改后的缓存中的数据没有及时刷新到内存及其他缓存中时，就会出现缓存一致性问题。</p>
<p>针对缓存一致性问题，硬件通过监控内存访问来建立底层一致性协议，保证共享内存的唯一性，但应用程序依旧需要通过互斥原语（比如锁），才能保证跨 CPU 访问（尤其是写入）数据的正确性，但是随着 CPU 数量的增加，访问同步共享数据会变得很慢。</p>
<p>2）缓存亲和度问题</p>
<p>一个进程在某个 CPU 上运行时，会在该 CPU 的缓存中维护许多状态，该进程下次在该 CPU 上运行时，由于缓存中的数据会执行的更快，但是如果该进程下次是在另一个 CPU 上运行，会由于需要重新加载数据而较慢，因此多核 CPU 调度应考虑到这种缓存亲和性问题，尽可能将进程保持在同一个 CPU 上。</p>
<p>多核 CPU 调度策略如下</p>
<p>1）单队列多处理器调度（SQMS），直接将原有的单核 CPU 调度策略用于多核 CPU 的情况，区别仅仅在于每个选择多个任务进行执行（选择的任务个数对应 CPU 的个数），实现起来很简单，但随着 CPU 的个数增大，多个 CPU 对于访问该队列的锁竞争增强，系统会花费越来越多的时间在锁的开销上，也无法很好的处理缓存亲和度的问题。</p>
<p>2）多队列多处理器调度（MQMS），每个 CPU 都有一个队列，每个队列可以使用不同的调度规则，系统依照一些启发性规则（比如随机或者选择较空的队列）将其放入某个调度队列中，这样可以避免数据共享带来的缓存一致性问题，也具备良好的缓存亲和度和可扩展性，但需要通过不断地任务迁移来实现良好的负载均衡性，任务迁移的实现方式及频率是问题所在。</p>
<p>并非所有的问题都有简洁明了最优的解决方案，真正的目标在于避免灾难。</p>
<h2 id="2-4-CPU-多级缓存"><a href="#2-4-CPU-多级缓存" class="headerlink" title="2.4 CPU 多级缓存"></a>2.4 CPU 多级缓存</h2><p>CPU 和主存的处理速度上存在一定的 gap，CPU 和主存之间的高速缓存可以避免 CPU 每次操作内存都进行长时间等待。高速缓存的特点是速度快、容量小，昂贵。在程序的运行过程中，会将运算需要的数据从主存中复制一份到 CPU 的高速缓存中，CPU 在计算时就可以直接从高速缓存中读取数据并直接向其写入数据，运算结束之后再将高速缓存中的数据刷新到主存中，并且随着 CPU 能力的不断提升，一层高速缓存渐渐地无法满足要求了，由此衍生出了多级缓存。</p>
<p>按照数据读取顺序和与 CPU 结合的紧密程度，CPU 缓存可以分为一级缓存（L1）、二级缓存（L2）、三级缓存（L3），每一级缓存中所存储的全部数据都是下一级缓存的一部分，这三级缓存的技术难度和成本是逐渐递减的，容量是逐渐递增的。多核 CPU 的每个核心都有各自的 L1（甚至 L2），并共享 L3（或者 L2）。在程序运行过程中，CPU 首先从 L1 中查询数据，如果没有再从 L2 中查询，如果没有再从 L3 中查询，如果没有再从主存中查询。</p>
<p>CPU 多级缓存之间的数据可能出现不一致的现象，通常通过在总线加锁或者缓存一致性协议来解决这个问题，早期的 CPU 使用前者，这是因为 CPU 和其他部件都是通过总线来进行通信的，但是这会使得加锁期间其他 CPU 无法访问内存，进而导致效率低下，因此缓存一致性协议逐渐成为主流，最出名的缓存一致性协议是 Intel 的 MESI 协议（不同的 CPU 可能采用不同的缓存一致性协议），MESI 协议中，每个缓存可能有四种状态</p>
<ul>
<li>M（Modified），数据有效，数据被修改了，修改结果仅存在于本缓存中，和主存中的数据不一致</li>
<li>E（Exclusive），数据有效，数据和主存中的数据一致，数据只存在于本缓存中</li>
<li>S（Shared），数据有效，数据和主存中的数据一致，数据存在于很多缓存中</li>
<li>I（Invalid），数据无效</li>
</ul>
<p>MESI 的核心是当 CPU 写数据时，如果发现写操作的变量是共享变量，就会将状态设置为 Modified， 并发出信号通知其他 CPU 将该变量的缓存置为 Invalid，当其他 CPU 需要读取该变量又发现自己的缓存中的该变量状态是 Invalid 时就会从主存中读取到缓存并设置状态为 Exclusive 或 Shared，当状态是 Exclusive 或 Shared 时就会直接从缓存中读取，当状态是 Modified 时就会先将数据写回主存再从主存中读取，这保证了每个缓存中的使用的共享变量的副本是一致的。</p>
<p>注：MESI 是硬件层面的协议，关注 CPU 缓存之间的一致性问题，是 CPU 设计的一部分，对于操作系统和上层应用来说是透明的；而 JMM（Java 内存模型）是 Java 中抽象出的软件层面的概念，关注 Java 多个线程之间的共享变量的可见性、有序性和原子性问题</p>
<h2 id="2-5-性能衡量指标"><a href="#2-5-性能衡量指标" class="headerlink" title="2.5 性能衡量指标"></a>2.5 性能衡量指标</h2><p>负载（Load）和 CPU 利用率是衡量系统性能的两个不同的指标</p>
<ul>
<li><p>CPU 利用率</p>
<ul>
<li>表示 CPU 正在执行指令（非闲置状态）的时间比例， 关注 CPU 的忙碌程度，高 CPU 利用率表示 CPU 正在积极工作，CPU 利用率越高越好</li>
<li>CPU 利用率急剧升高的检查方向有：内存泄漏导致的频繁 GC，频繁创建耗时对象，死循环等</li>
</ul>
</li>
<li><p>Load</p>
<ul>
<li>通常指一段时间内系统等待处理的的工作量，关注系统中等待运行的工作量，高 Load 意味着有很多进程在等待使用 CPU，可能会导致系统响应的变慢甚至死机，Load 越低越好</li>
<li>Load Average 通常表示在过去一段时间内运行队列的平均长度，运行队列长度是指在某一时刻处理就绪状态和运行状态的进程数量的和（包括正在使用 CPU 和进程和等待 CPU 的进程）</li>
<li>CPU 使用、内存使用、I/O 消耗三者共同构成了 Load，任意一项使用过多都会导致 Load 急剧增大，可以根据机器的实际情况，以最近一个月的 Load 平均值为基线，日常 Load 一旦与基线差距太多就需要介入检查</li>
<li>一般检查方向有：机器本身的硬件性能问题，应用内存泄漏导致的频繁 GC，死锁导致的长时间阻塞，大字段的读写，慢 SQL 等</li>
</ul>
</li>
</ul>
<h1 id="3、虚拟化内存"><a href="#3、虚拟化内存" class="headerlink" title="3、虚拟化内存"></a>3、虚拟化内存</h1><p>用户程序生成的每个地址都是虚拟地址，每个进程访问自己的私有且连续的虚拟地址空间，多个进程间的虚拟地址彼此独立，操作系统高效地将虚拟地址映射到机器的物理内存上，而进程对此过程毫无感知，这就是<strong>虚拟化内存</strong>。</p>
<h2 id="3-1-进程地址空间"><a href="#3-1-进程地址空间" class="headerlink" title="3.1 进程地址空间"></a>3.1 进程地址空间</h2><p>操作系统将物理内存抽象为地址空间/虚拟内存，程序中打印出来的地址都是地址空间/虚拟内存中的虚拟地址，只有操作系统和硬件才知道物理地址。一个进程的地址空间/虚拟内存是运行的程序所看到的系统中的内存，包含运行的程序的所有内存状态，比如代码指令，用来保存函数调用信息的栈，以及用来管理动态分配的堆等。</p>
<p>UNIX/C 程序使用<code>malloc()</code>和<code>free()</code>来在堆内存中申请和释放空间，Java 程序使用<code>new</code>来分配一个新对象的内存，并由 JVM 自动回收不再引用的内存，无需显式释放内存。关于内存分配和释放的一些常见错误和后果如下</p>
<ul>
<li><p>忘记分配内存就直接使用引用，会发生段错误</p>
</li>
<li><p>没有分配足够的内存，会产生内存溢出</p>
</li>
<li><p>忘记初始化分配的内存就使用引用，可能会读取到一些随机和有害的东西</p>
</li>
<li><p>忘记释放内存，会产生内存泄漏进而导致内存不足，需要重新启动（进程退出时操作系统会清理释放其分配的所有页面）</p>
</li>
<li><p>在使用完之前就释放内存，这种错误称为悬挂指针，可能会导致程序崩溃或覆盖有效的内存</p>
</li>
<li><p>重复释放内存或者错误的使用<code>free()</code>，产生的结果是不确定的，崩溃是常见的</p>
</li>
</ul>
<h2 id="3-2-空闲空间管理"><a href="#3-2-空闲空间管理" class="headerlink" title="3.2 空闲空间管理"></a>3.2 空闲空间管理</h2><p>用于管理空闲空间的数据结构通常称为空闲列表（不一定真的是列表这一数据结构），该结构包含了管理内存区域中所有空闲块的引用。如果将需要管理的空间被划分为固定大小的单元，那么就只需要维护这些大小固定的单元的列表，如果有请求，就返回列表中的第一项。而用户级的内存分配库（<code>malloc()</code>和<code>free()</code>），或者操作系统分段都需要管理大小不同的空间单元（malloc 库管理进程中堆的页，操作系统管理进程的地址空间）。</p>
<p>理想的分配程序可以同时保证快速和碎片最小化，一些基本的策略选择如下（但由于分配及释放的请求序列由用户程序决定，是随意的，任何特定的策略在某组不匹配的输入下都会变得非常差）</p>
<p>1）最优匹配，遍历整个空闲列表，找到和请求大小一样或更大的空闲块，在这组候选中选择最小的一块返回，只需要遍历一次，尽量避免了空间浪费。</p>
<p>2）最差匹配，遍历整个空闲列表，找到和请求大小一样或更大的空闲块，在这组候选中选择最大的一块并将其分割出满足用户需求的块返回后，将分割剩余的块再加入空闲列表，只需要遍历一次，但会导致过量的碎片，还有很高的开销。</p>
<p>3）首次匹配，遍历空闲列表直到找到一个足够大的块，将请求的空间返回，将剩余的空间再加入空闲列表，不需要完整遍历整个空闲列表，有速度优势，但有时会让空闲列表开头的部分有很多碎片，因此分配程序如何管理空闲列表的顺序就变得很重要，可以令空闲块按内存地址有序，那么合并操作就会很容易，从而减少碎片。</p>
<p>4）下次匹配，与首次匹配的区别在于每次查找时都维护一个指针，指向上一次查找数据的位置，那么每次查找就从指针指向位置开始查找，从而将查询操作扩散到整个列表中去，而不是集中在列表开头，性能与首次匹配很接近，但避免了完整遍历整个列表。</p>
<p>5）分离空闲列表，如果某个应用程序经常申请一种或几种大小的内存空间，那就用一个独立的列表，只管理这样大小的对象，在这个独立列表中，碎片将不再是问题，而其他大小的请求都交给更通用的内存分配程序。</p>
<p>6）伙伴系统，空闲空间从概念上被看成大小为 2^N 的大空间，当有一个内存分配请求时，空闲空间被递归地一分为二，直到刚好可以满足请求的大小，然后返回给用户，这种策略的特殊之处在于很容易确定任意一个块的伙伴（和块一样大小），当块被释放时，分配程序会检查伙伴块是否空闲，如果是，就合并这两块，这个递归合并过程继续上溯，直到合并这个内存区域，或者某一个块的伙伴还没有被释放。</p>
<h2 id="3-3-硬件地址转换"><a href="#3-3-硬件地址转换" class="headerlink" title="3.3 硬件地址转换"></a>3.3 硬件地址转换</h2><p>应用程序每次使用内存引用时，硬件会通过地址转换将指令中的虚拟地址重定位/转换为数据实际存储的物理地址，而操作系统则需要设置好硬件，管理好内存，记录被占用和空闲的内存位置。操作系统应当保证应用程序可以以任何方式访问到自己的内存空间，且只能访问它自己的内存空间。</p>
<h3 id="3-3-1-MMU"><a href="#3-3-1-MMU" class="headerlink" title="3.3.1 MMU"></a>3.3.1 MMU</h3><p>每个 CPU 有两个硬件寄存器：基址寄存器和界限寄存器（有时称为限制寄存器），统称为内存管理单元（MMU）。</p>
<p>当程序真正开始执行时，操作系统会为进程的地址空间找到内存空间，决定进程在物理内存中的实际加载地址，将其标记为被占用，将起始地址记录在基址寄存器中，<strong>而进程所产生的所有内存引用，只需加上基址寄存器中的内容，就重定位/转换为数据实际存储的物理地址（界限寄存器则用于确保这个物理地址在进程地址空间的范围内）</strong>，这个地址转为过程完全由硬件处理，没有操作系统的介入。</p>
<p>当进程结束时（正常退出或因行为不端被强制终止），操作系统会回收进程所有的内存，根据需要清除相关的数据结构，将其加入空闲空间列表，后续可给其他进程或者操作系统使用。</p>
<p>当上下文切换时，操作系统在内核模式下，通过一些特殊的特权指令（由硬件提供）来修改（保存和恢复）基址寄存器和界限寄存器，用户模式下的应用程序无法执行特权指令，而在应用程序尝试修改基址寄存器和界限寄存器，或者尝试非法访问内存时，CPU 会产生异常，并安排操作系统的异常处理程序去进行相关处理（通常是终止进程）。</p>
<p>当进程停止（没有占用 CPU 运行）时，操作系统可以改变其地址空间的物理位置，即将地址空间拷贝到新位置，在进程结构中更新保存的基址寄存器，当该进程恢复执行时，它的新基址寄存器就会被恢复，然后再次开始运行，这是它的指令和数据就都在新的内存位置了。</p>
<p>这种运行时发生的地址转换技术一般被称为动态重定位，动态重定位可以在进程开始运行后改变其地址空间，使得用户能够将地址空间放在物理内存的任何位置，同时又能确保进程只能访问自己的地址空间。但是该技术将进程的地址空间放在固定大小的槽块中，当进程的栈和堆并不大时，会导致该<strong>进程所占据的这块内存区域中大量空间被浪费，即导致大量内部碎片</strong>，此外，当剩余可用的内存无法提供完整的地址空间时，将无法继续运行新进程。</p>
<h3 id="3-3-2-分段"><a href="#3-3-2-分段" class="headerlink" title="3.3.2 分段"></a>3.3.2 分段</h3><p>一个段是地址空间里的一个连续定长的区域，在典型的地址空间中有三个逻辑不同的段：代码、栈和堆。分段就是给地址空间内的每个逻辑段分配一对基址寄存器和界限寄存器，<strong>此时进程所产生的内存引用，需要先减去其所在段的起始虚拟地址（段内偏移），再加上这个段所对应的基址寄存器中的内容，就重定位/转换为数据实际存储的物理地址，这个段所对应的界限寄存器则用于确保这个物理地址在段的地址空间的范围内</strong>（进程虚拟地址所使用的段以及各个段的起始地址可以在进程虚拟地址的开头几位来显式地标识出来）。</p>
<p>这种分段的地址转换使得操作系统可以将不同的段放到不同的物理内存区域，只有进程已用的内存才在物理内存中分配空间，避免了大量内存碎片，能更好地支持稀疏地址空间，算法简单，开销小，速度快。此外，为了进一步节省内存，可以在进程地址空间之间共享一些物理内存段（比如代码共享），因此，物理内存中的一个段可以映射到多个虚拟地址空间。</p>
<p><strong>由于每个进程都有一些段，每个段的大小也可能不同，那么物理内存中会出现很多不连续的空闲空间的奇怪小洞，很难分配给新的段或者扩大已有的段，这些空间被称为外部碎片</strong>。为了减少外部碎片，操作系统先停止进程，将被停止进程的数据复制到连续的内存区域中，改变它们的段寄存器的值，指向新的物理地址，然后再切换到原进程，并得到足够大的连续空闲物理内存，不过这样的紧凑物理内存的成本很高，一般会占用大量的 CPU 时间。</p>
<p>比紧凑物理内存更简单的做法是利用空闲列表管理算法，试图保存大的内存块用于分配，相关的算法有很多，过多的算法也说明这个问题并没有最好的解决方式（无论哪个算法，都无法完全消除外部碎片，只能是试图减小它）。但是如果在一开始分配的时候就控制每个段的大小都保持一致，就可以避免这些外部碎片的出现。</p>
<h3 id="3-3-3-分页"><a href="#3-3-3-分页" class="headerlink" title="3.3.3 分页"></a>3.3.3 分页</h3><p>不同于大小不一的逻辑段，分页指操作系统将进程地址空间分割成固定大小的单元页从而避免空间碎片化，相应地，将物理内存看成是定长槽块的阵列，叫做页帧，每个这样的页帧包含一个虚拟内存页，连续的虚拟页可能对应不连续的位于不同位置（位于物理内存或硬盘设备）的物理页帧。</p>
<p>操作系统为每个进程保存一个页表，用于记录地址空间的每个虚拟页号（VPN）所对应的页表项，页表项中有页对应的物理页帧号（PFN）本身以及许多不同的位</p>
<ul>
<li>有效位用于指定特定地址转换是否有效（进程地址空间中未被使用的都被标记为无效），无效的地址空间不会被分配物理页帧，如果进程尝试访问这种无效内存，操作系统就会终止进程</li>
<li>保护位/读写位表明页是否可以读取、写入和执行，以保护位不允许的方式访问页，操作系统就会终止进程</li>
<li>存在位表示该页是在物理内存还是在硬盘上（交换操作系统将很少使用的页面移到硬盘，硬盘和物理内存间的页交换用于提供大于物理内存的地址空间）</li>
<li>脏位表明页面被带入内存后是否被修改过</li>
<li>参考位/访问位有时用于追踪页是否被访问，也用于确定哪些页很受欢迎，因此应该保留在内存中</li>
<li>用户/超级用户位用于确定用户模式进程是否可以访问该页面</li>
</ul>
<p>页表可以变得非常大，比小段表或基址/界限对要大得多，所以 MMU 并不用于存储当前正在运行的进程的页表，而是将每个进程的页表都存储在内存中，<strong>此时针对进程所产生的内存引用，首先将需要访问的内存引用转换为二进制形式，从中检查其对应的虚拟页号以及页内偏移量，接着通过页表的基址寄存器和界限寄存器查找页表所在的物理地址，从页表中找到虚拟页号所对应的物理页帧，物理页帧中对应的页内偏移量就是需要数据实际存储的物理地址（将虚拟地址的二进制中的代表虚拟页号的高位转换为物理页帧号，低位的代表页内偏移量的位保持不变，就得到了真实的物理地址的二进制）</strong>。</p>
<p>由于页是固定大小的单元，分页不会导致外部碎片，且支持稀疏虚拟地址空间（进程地址空间中未被使用的内存不会被分配物理页帧），尽可能减少了进程地址空间的内部碎片（依旧存在页内内部碎片），但基于分页的地址转换过程额外开销很多（需要一次额外的内存访问用于访问页表），导致系统运行速度过慢，并占用太多额外内存（内存被页表塞满而不是有用的应用程序数据），导致内存浪费。</p>
<h3 id="3-3-4-TLB"><a href="#3-3-4-TLB" class="headerlink" title="3.3.4 TLB"></a>3.3.4 TLB</h3><p>地址转换旁路缓冲存储器（TLB）是频繁发生的虚拟到物理地址转换的硬件缓存，可以加速基于页表的地址转换，<strong>每次内存访问时，首先从虚拟地址中提取虚拟页号，然后硬件检查 TLB 中是否有该虚拟页号所对应的 TLB 项，如果有就可以直接从 TLB 项中得到物理页帧号，与虚拟地址中的偏移量组合得到期望的物理地址，而无需访问页表（页表有全部的转换映射），如果没有命中 TLB，硬件抛出异常，暂停当前指令流，将特权级别提升至内核模式，操作系统执行“TLB 未命中程序”来按照上一节所述过程查找页表并更新 TLB（为了充分利用局部性原理），接着硬件会重试，此时就会命中 TLB</strong>。</p>
<p>一条 TLB 项包含虚拟页号，物理页帧号以及其他位。其他位中的保护位用来标识该页是否有访问权限（例如代码页被标识为可读和可执行，堆的页被标识为可读和可写）；有效位用来标识该项是不是有效地转换映射（不同于页表项中的有效位用于标识该页是否被进程申请使用，TLB 的有效位只是指出该 TLB 项是否是缓存了地址转换映射，比如系统启动时，所有的 TLB 项通常被初始化为无效状态，一旦程序开始运行并访问自己的虚拟地址，TLB 就会慢慢填满，有效的项很快会充满 TLB）。在上下文切换时，确保将要运行的进程不会错误地使用前一个进程的虚拟地址到物理地址转换映射，此时可以将所有 TLB 项的有效位设置为无效，也可以给所有的 TLB 项添加一个地址空间标识符/进程标识符来区分属于不同进程的 TLB 项。</p>
<p>大的缓存注定慢，缓存如果要追求快速，那缓存就必须小，TLB 是小而快的缓存，这种结构也导致一些问题</p>
<ul>
<li>TLB 未命中：命中 TLB 时，地址转换的时间开销可以忽略不计（此时性能就像内存没有虚拟化一样），但如果未命中，那么就必须访问页表来进行地址转换，会带来很大的内存访问开销（尤其是页表结构复杂时），相对于大多数 CPU 指令，内存访问的开销很大</li>
<li>超出 TLB 覆盖范围：在向 TLB 插入新项时，会替换一个旧项，TLB 中的页项数是保持不变的，如果一个程序短时间内访问的页数超过了 TLB 中的页数，就会产生大量的 TLB 未命中，这种现象称为超出 TLB 覆盖范围，是相当严重的问题</li>
<li> TLB 未命中的无限递归：为了避免 TLB 未命中的无限递归，可以把操作系统关键时刻需要使用的代码和数据（比如“TLB 未命中程序”）也放到 TLB 中</li>
</ul>
<h3 id="3-3-5-小页表"><a href="#3-3-5-小页表" class="headerlink" title="3.3.5 小页表"></a>3.3.5 小页表</h3><p>更小的页表可以降低页表的内存消耗，减少页表本身对内存空间的浪费（作为代价， TLB 未命中时的处理也就更加复杂），小页表有以下实现方式</p>
<ul>
<li>更大的页，可以把关键数据结构放在程序地址空间的某些区域，这些区域被映射到更大的页（对更大的页的支持通常被数据库管理系统利用，它们的数据结构比较大，而且是随机访问），更大的页可以增加 TLB 的有效覆盖率，但会导致页内产生太多内部碎片</li>
<li>混合分段分页，此时不再为进程的整个地址空间提供单个页表，而是为每个逻辑分段分别提供一个页表，每个段的基址/界限寄存器保存该段的页表的开头/结尾物理地址，但依旧存在分段导致的外部碎片问题</li>
<li>更稀疏也更复杂的多级页表结构（树形数据结构），并用页目录来记录页表的哪些页被分配了页表项并驻留在内存中<ul>
<li>多级页表无需连续驻留在物理内存中</li>
<li>多级页表所使用的内存空间与进程地址空间正在使用的内存量成比例</li>
<li>在命中 TLB 时，由于无需访问页表，性能没有变化</li>
<li>在TLB 未命中时，需要从内存加载多次（次数取决于页表的级数）才能从页表中获得正确的页表项，TLB 未命中的成本更高了</li>
<li>以“页表本身的所有内容都能放入一页”为目标来确定页表的级数</li>
</ul>
</li>
<li>反向页表，页表中的项代表物理页（而非虚拟页），页表项记录哪个进程正在使用此物理页，以及该进程的哪个虚拟页映射到此物理页</li>
<li>将页表的一部分交换到磁盘，即内存中只保留小部分页表</li>
</ul>
<h2 id="3-4-更大存储空间"><a href="#3-4-更大存储空间" class="headerlink" title="3.4 更大存储空间"></a>3.4 更大存储空间</h2><h3 id="3-4-1-硬盘设备"><a href="#3-4-1-硬盘设备" class="headerlink" title="3.4.1 硬盘设备"></a>3.4.1 硬盘设备</h3><p>并不是所有的正在运行的进程的地址空间/虚拟内存都能放入物理内存，即并不是所有的页都常驻在物理内存中，为了支持更大的地址空间，操作系统将当前没有在使用的地址空间用一个大而慢的设备（硬盘，SSD 等）存储起来，从而构建出比真实物理内存更大的虚拟内存的假象。</p>
<p>硬盘上有一部分空间（称为<strong>交换空间</strong>）用于物理页在内存和硬盘之间的移入和移出，操作系统以页为单位读取或者写入交换空间，硬盘交换空间的大小决定了系统在某一时刻能够使用的最大内存页数，即最大虚拟内存空间。当内存空间已满或者接近满时，没有足够的空间内存用于存储交换空间换入的页，此时操作系统需要换入页的同时换出一个页到交换空间中，或者操作系统通过一个<strong>交换守护进程或页守护进程</strong>来在一定条件下提前换出页，始终在内存中预留一些空闲空间（只要操作系统在运行，这一过程就不会停歇）。</p>
<p>页表的页表项通过存在位来表示该页是在物理内存还是在磁盘上，访问不在物理内存中的页（当然也不在 TLB 中）就称为页错误，此时硬件触发异常，并将控制权移交给操作系统，操作系统会执行“页错误处理程序”，<strong>首先从页表项中得到所需的页的硬盘地址，并检查内存是否有可用的空闲页，如果没有则通知后台分页线程按需释放页，当线程释放一定数目的页时会唤醒原来的线程，原线程发送请求到硬盘，将页读取到内存中，当硬盘 I/O完成时，操作系统会在页表项中将此页标记为存在，在页表项中更新此页的物理页帧号，并将此页更新到 TLB 中，最后硬件重试访问指令，此时命中 TLB，直接得到所需要的物理内存地址</strong>。I/O 操作是昂贵的，当硬盘 I/O 在运行时，进程将处于阻塞状态，操作系统可以自由地运行其他可执行的进程。</p>
<p>将多个要写入的页聚集或分组，同时执行多个交换过程，这种合并操作可以一次写入原本多次要写入的数据，减少硬盘的寻道和旋转开销，从而提高硬盘的效率。</p>
<h3 id="3-4-2-交换策略"><a href="#3-4-2-交换策略" class="headerlink" title="3.4.2 交换策略"></a>3.4.2 交换策略</h3><p>如果换出了不合适的页会导致巨大的性能损失（程序以磁盘的速度运行，比内存速度慢一万到十万倍），交换策略用于选择需要换出的页。</p>
<p>1）FIFO，页在进入内存时放入一个队列，永远换出队列尾部的页，实现相当简单</p>
<p>2）RAND，随机选择需要换出的页，实现相当简单</p>
<p>3）LRU，以历史访问情况作为参考，永远换出最不经常使用的页，记录并查找最少访问页的代价可能比较高，且不会在多个进程间公平分享内存</p>
<p>4）近似 LRU，不要求必须找到绝对最旧的页，只是找到差不多最旧的页作为换出页，页命中率是接近 LRU，但是实现的代价可能会小很多</p>
<p>对于符合局部性原理的程序，使用 LRU 效果最佳；对于随机访问页的程序，LRU，FIFO 甚至是随机换出页的效果差别都不大；对于顺序访问页的程序，使用随机换出页的方式最佳，此时 LRU 和 FIFO 的效果都很差。</p>
<p>换出干净页（指内存没有修改过的页）只需将其从内存中去掉，无需写回磁盘，换出的成本很低，而换出脏页（内存修改过的页）必须将其写回磁盘，这很昂贵，因此一般倾向于优先换出干净页。</p>
<h1 id="4、并发"><a href="#4、并发" class="headerlink" title="4、并发"></a>4、并发</h1><p>一方面，操作系统本身就是一个并发程序，它必须小心的访问自己的内存；另一方面，操作系统需要用锁和条件变量来支持多线程并发运行的应用程序。</p>
<h2 id="4-1-基于线程的并发"><a href="#4-1-基于线程的并发" class="headerlink" title="4.1 基于线程的并发"></a>4.1 基于线程的并发</h2><h3 id="4-1-1-规范"><a href="#4-1-1-规范" class="headerlink" title="4.1.1 规范"></a>4.1.1 规范</h3><ul>
<li>多线程程序会有多个执行点（即多个程序计数器，多个栈），在共享的进程空间中存取指令并执行，共享堆内或者其他全局可访问的数据</li>
<li>当多个线程在同一个 CPU 上执行时，就需要进行线程的上下文切换，与进程上下文切换不同的是，线程的上下文切换时进程地址空间保持不变，则不需要切换当前使用的页表</li>
<li>每个线程都有自己的栈和线程局部变量，这都是线程私有的，其他线程不应访问，线程也不应返回自己的局部变量（因为线程返回时线程局部变量所引用的内存已经释放了）</li>
<li>同一进程的多个线程访问共享变量的代码段称为临界区，临界区不能由多个线程同时执行</li>
<li>通过互斥量/锁来避免临界区的不合时宜的中断和线程切换，从而保证临界区的操作原子性，当线程需要抢夺多个锁来才能进入临界区时，需要注意预防死锁</li>
<li>通过条件变量来作为线程间的通知等待信号，实现线程间的交互，也保证多线程按照期望的顺序执行</li>
<li>尽可能简单，尽可能只在真正需要时才使用并发，尽可能避免复杂的不必要的线程交互，尽可能使用已被证实的线程交互方式</li>
</ul>
<h3 id="4-1-2-线程的实现"><a href="#4-1-2-线程的实现" class="headerlink" title="4.1.2 线程的实现"></a>4.1.2 线程的实现</h3><p>线程的实现方式主要如下</p>
<ul>
<li>使用内核线程实现<ul>
<li>内核线程就是直接由操作系统内核支持的线程，这种线程由内核来完成线程切换，内核通过调度器来对线程进行调度，并负责将线程的任务映射到各个 CPU 上，并向应用程序提供 API 接口来管理线程</li>
<li>应用程序一般不会直接使用内核线程，而是使用轻量级进程（内核线程的一种高级接口），这才是通常意义上所讲的线程，每个轻量级进程都由一个内核线程支持，只有先支持内核线程，才能有轻量级进程</li>
<li>轻量级进程由内核线程支持，因此其局限在于所有操作（创建、调度等）都需要进行系统调用，需要在用户态和内核态之间切换，需要消耗一定的内核资源，一个系统能够支持的轻量级进程的数量是有限的</li>
</ul>
</li>
<li>使用用户线程实现<ul>
<li>在用户空间创建线程库，通过运行时系统来完成线程的管理，这种线程的操作完全是在用户空间由用户程序自行完成的，操作系统的内核仅仅只是管理进程，而对进程中的这种线程无感知，这种线程的操作也不涉及系统调用</li>
<li>在多核 CPU 系统中，如果将线程映射到多个 CPU 上是一个难题</li>
</ul>
</li>
<li>使用用户线程 + 轻量级进程混合实现<ul>
<li>线程的创建通过线程库在用户空间完成，但是线程的调用由内核来完成，多个用户线程通过多路复用来复用多个内核线程</li>
</ul>
</li>
</ul>
<h3 id="4-1-2-互斥量-锁"><a href="#4-1-2-互斥量-锁" class="headerlink" title="4.1.2 互斥量/锁"></a>4.1.2 互斥量/锁</h3><p>锁实质是一个互斥变量（mutex）。</p>
<ul>
<li>锁变量保存了锁在某一时刻的状态，可用（available/unlocked/free）代表没有线程持有锁，被占用（acquired/locked/held）表示有一个线程持有锁，正处于临界区</li>
<li>锁变量还隐藏了其他的信息，比如持有锁的线程，请求获取锁的线程队列，这些信息会隐藏起来，锁的使用者不会发现这些信息</li>
<li>只有持有锁变量的线程才能进入临界区，线程只有退出临界区才释放锁变量，因此，锁可以用来保证临界区代码段能够像单条原子指令一样执行</li>
<li>通常使用不同的锁来保护不同的数据和结构，从而尽可能降低锁的粒度/保护范围，细粒度的锁允许更多的线程进入临界区</li>
<li>锁为程序员提供了最小程度的调度控制，将原本由操作系统调度的混乱状态变得可控程度更高一点</li>
</ul>
<p>应该尽可能避免使用锁，除非确信必须使用，高效的锁应当以低成本的硬件和操作系统支持来提供正确互斥，公平竞争以及良好的性能。</p>
<p>1）基于中断</p>
<ul>
<li>对于操作系统本身，可以通过在进入临界区之前关闭中断，在结束临界区之后打开中断，那么在临界区内不会由于中断导致线程切换，从而提供了正确互斥</li>
<li>但是关闭中断的方式无法工作在多 CPU 上，因为其他线程可以运行在其他 CPU 上，也不允许应用于应用程序，因为这会令操作系统失去对应用程序的控制，效率低，甚至会导致应用程序无法工作</li>
</ul>
<p>2）基于自旋（是最简单的一种锁）</p>
<ul>
<li>硬件提供三种原子操作指令（测试并设置指令、比较并交换指令、获取并增加指令），线程一直自旋来尝试执行某种指令，只有一个线程能够执行成功，即只有一个线程能够获取锁，从而提供了正确互斥</li>
<li>基于测试并设置指令或比较并交换指令的自旋锁不保证公平性，自旋的线程在竞争条件可能会永远自旋，即饿死，而基于获取并增加指令的自旋锁可以保证公平性</li>
<li>非抢占式的单 CPU 无法使用自旋锁，因为占据 CPU 的自旋线程永远不会放弃 CPU，而多 CPU 以及抢占式的单 CPU 则存在一些性能问题，因为竞争锁的线程会自旋整个 CPU 时间片，N 个线程竞争时会浪费 N-1 个 CPU 时间片</li>
</ul>
<p>3）基于队列和休眠</p>
<ul>
<li>操作系统提供原语<code>yield()</code>，令线程主动放弃 CPU 进入休眠，当线程不能获取锁时不进入自旋，而是将自己加入队列，然后让出 CPU 进入休眠</li>
<li>通过队列来控制哪个线程会获得锁，实现了公平</li>
<li>通过休眠来避免自旋线程浪费整个时间片，但系统可能依旧存在频繁的线程上下文切换</li>
</ul>
<p>4）两阶段锁（由 Linux 操作系统提供）</p>
<ul>
<li>两阶段锁的第一阶段会先自旋一段时间，希望可以获取那种即将被释放的锁，如果第一阶段没有获取锁，那么第二阶段会进行休眠直到锁可用，一般通过固定自旋的次数来区分第一阶段和第二阶段</li>
</ul>
<h3 id="4-1-3-条件变量"><a href="#4-1-3-条件变量" class="headerlink" title="4.1.3 条件变量"></a>4.1.3 条件变量</h3><p>条件变量用于帮助线程判断是否某一条件满足（比如其他线程是否执行完毕），可以作为线程间的通知等待信号，从而实现线程间的交互（应当尽可能减少不必要的线程交互），也保证多线程按照期望的顺序执行。</p>
<p>条件变量实质是一个显式队列，当线程持有锁并发现该条件不满足时，线程把自己加入队列，然后通过调用<code>wait()</code>进入休眠，当另外某个线程持有锁并改变上述条件状态后，就通过调用<code>signal()</code>来尝试唤醒等待该条件的线程，等待该条件的线程则结束休眠并尝试获取锁，若获取到锁则可以继续运行。</p>
<ul>
<li><p>始终使用<code>while</code>而不是<code>if</code>来判断条件变量</p>
</li>
<li><p>在调用<code>wait()</code>和<code>signal()</code>时，应当确保已经持有锁，当<code>wait()</code>和<code>signal()</code>的返回时则代表锁被释放，这样可以确保<code>wait()</code>和<code>signal()</code>不会同时被调用，避免正在调用<code>wait()</code>的线程错过唤醒信号</p>
</li>
<li><p>根据等待条件的不同，合理使用不同的条件变量，以便正确地发送信号，明确真正应该被唤醒的线程，尽量避免广播式唤醒所有等待线程</p>
</li>
</ul>
<p>补充：信号量是有一个整数值（这个值就是等待线程的个数，但通常不会暴露给信号量的使用者）的对象，信号量根据这个整数值来决定其行为，可以实现不同功能的锁以及条件变量。</p>
<h3 id="4-1-4-数据结构"><a href="#4-1-4-数据结构" class="headerlink" title="4.1.4 数据结构"></a>4.1.4 数据结构</h3><p>高效的并发数据结构应当保证功能正确，线程安全以及良好的并发访问性能，理想情况下，多处理器上运行的多线程就像单线程一样快，这种总工作量增多，但是并行执行完成任务的时间没有增加的状态称为完美扩展。</p>
<p>如果数据结构导致的运行速度不是太慢，那就足够了，如果简单的方案就能工作，就不需要复杂的设计，如果让应用的某一小部分变快，却没有提高整体的性能，其实没有价值，不成熟的优化是坏事的根源。</p>
<p>1）计数器（最简单的一种数据结构）</p>
<p>可扩展的计数器很重要，否则运行在 Linux 上的工作在多核机器上将遇到严重的扩展性问题，懒惰计数器就是一个扩展的并发计数器。</p>
<p>懒惰计数器通过多个局部计数器和一个全局计数器来实现一个逻辑计数器，其中每个 CPU 核心有一个局部计数器，每个局部计数器以及全局计数器都有一个锁，此时同一个 CPU 上的线程通过局部锁来保证线程安全，不同 CPU 上的线程不会竞争保证良好的可扩展性，此外局部计数器通过全局锁来定期将值转移给全局计数器并将自身置零，更新全局计数器的频率越高，计数器的准确性越高，但性能会变差，准确性和性能之间存在权衡。</p>
<p>2）并发链表</p>
<p>如果每个节点都有一个锁，那么与整个链表一个锁相比，允许更多的线程去访问链表，提升了链表操作的并发程度，但遍历链表时，需要频繁的获取锁和释放锁，开销巨大，很难比单锁链表的更快。更多并发不一定更快，如果方案带来了大量的开销，那么高并发就没有什么意义。</p>
<p>3）并发队列</p>
<p>并发队列使用两个锁，一个队头锁，一个队尾锁，这使得入队和出队可以并发执行。</p>
<h2 id="4-2-基于事件的并发"><a href="#4-2-基于事件的并发" class="headerlink" title="4.2 基于事件的并发"></a>4.2 基于事件的并发</h2><p>针对基于线程的并发，开发者只是创建了线程，然后就依赖操作系统能够合理地调度线程，开发者无法控制多线程在某一时刻的调度，正确处理基于线程的并发，并且实现在各种不同负载下都能够良好运行的通用调度，是很有难度的。</p>
<p>并发并不仅仅是基于线程实现，一些 GUI 应用或者某些类型的网络服务器常常采用基于事件的并发方式</p>
<ul>
<li>采用基于事件的并发通过事件处理程序来显式地控制对各个事件的调度</li>
<li>对于基本事件的并发，某种 I/O 导致的阻塞会阻止所有进展，为了避免长期甚至无期限地阻塞，通常会指定超时并使用异步 I/O（对于不支持异步 I/O 的系统，纯基于事件的并发无法实现）</li>
<li>异步 I/O 使应用程序能够发出 I/O 请求，并在 I/O 完成之前立即将控制权返回给调用者，需要提供另外的接口让应用程序能够确定各种 I/O 是否已完成，或者通过某种信号在异步 I/O 完成时通知应用程序（应用程序通过预先设置的信号处理程序来对捕捉到的信号进行处理）</li>
<li>基于事件的并发很难在发出异步 I/O 时，打包一些程序状态，以便下一个事件处理程序在 I/O 最终完成时使用，这不同于基于线程的并发直接由线程栈来保存状态信息</li>
</ul>
<h1 id="5、持久化"><a href="#5、持久化" class="headerlink" title="5、持久化"></a>5、持久化</h1><h2 id="5-1-I-O-设备"><a href="#5-1-I-O-设备" class="headerlink" title="5.1 I/O 设备"></a>5.1 I/O 设备</h2><h3 id="5-1-1-基本概念"><a href="#5-1-1-基本概念" class="headerlink" title="5.1.1 基本概念"></a>5.1.1 基本概念</h3><p>一个标准设备包含1）向系统其他部分展现的硬件接口和交互协议，大概会包含一些存储设备状态、接收命令以及设备数据的寄存器；2）实现设备对外展示接口的内部结构，可能是几个芯片甚至成百上千行固件（固件指硬件设备中的软件）。CPU 通过某种专有的内存总线连接到系统内存，I/O 设备（显卡）通过常规的 I/O 总线连接到系统，磁盘、鼠标及其他最慢的设备通过外围总线连接到系统。</p>
<p>操作系统通过操作系统通过 I/O 指令（I/O 指令是特权指令，操作系统是唯一可以直接与设备交互的实体）或者内存映射 I/O （内存映射 I/O 指硬件将设备寄存器作为内存地址提供）来与设备进行交互，通过设备驱动程序（是操作系统中明确知道设备如何工作的软件，驱动程序代码在整个内核代码中占比非常大）将设备接口纳入操作系统。因此，操作系统可以通过调用设备接口轮询确认设备是否进入可以接受命令的就绪状态，设备就绪后，操作系统发数据以及命令到设备，设备执行命令，操作系统轮询设备是否执行完成命令。</p>
<p>为了避免操作系统轮询浪费 CPU 时间片，可以由设备在命令完成后抛出一个硬件中断，引发 CPU 跳转执行预先定义好的中断服务程序，而在中断抛出之前，操作系统可令 CPU 切换至其他进程，但对于处理操作系统请求很快的高性能设备来说，使用中断反而会拖累性能，此时使用轮询更佳。此外，网络场景也更适合使用轮询，因为此时大量的数据包请求中断很有可能会导致操作系统发生活锁，即不断处理中断而无法处理用户层的请求，而轮询的方式可以更好地控制系统的行为，允许 Web 服务器先服务一些用户请求，再检查网卡设备是否有更多数据包到达。</p>
<h3 id="5-1-2-磁盘驱动器"><a href="#5-1-2-磁盘驱动器" class="headerlink" title="5.1.2 磁盘驱动器"></a>5.1.2 磁盘驱动器</h3><p>磁盘驱动器作为 I/O 设备中的一种，一直是计算机系统中持久数据存储的主要形式。磁盘驱动器有一个或多个圆形盘片，磁盘的所有盘片都围绕主轴连接在一起，主轴连接到一个电机，当驱动器接通电源时，电机以一个恒定的速度旋转盘片。盘片的两面都称为表面，表面有磁性层，一个表面包含数以千计的同心圆，每个同心圆是一个磁道，数据在磁道中被编码，当需要读写时，磁盘臂在表面上移动，将磁头定位在期望的磁道上，通过引入磁性变化来永久存储数据，因此即使断电，磁盘驱动器也能持久存储数据位。</p>
<p>磁盘盘片表面的磁道可以被划分为不同扇区（512 字节块），现代磁盘驱动器可以视为一组扇区，扇区编号是驱动器的地址空间，磁盘只能以扇区大小的块或其倍数写入，但是驱动器制造商唯一保证的是单个 512 字节的写入是原子的。当需要读写时，磁盘驱动器首先需要将磁盘臂移动到正确的磁道（这就是寻道过程），接着等待期望的扇区旋转到磁头下（这种旋转等待时间称为旋转延迟），最后数据从表面读取或写入表面，这就是完整的 I/O 过程（寻道和旋转都是昂贵的磁盘操作）。应当尽可能以顺序方式将数据传输到磁盘，并从磁盘传输数据，如果顺序不可行，至少应考虑以大块传输数据，越大越好，如果 I/O 是以小而随机方式完成的，则性能将受到显著影响。</p>
<p>现代磁盘驱动器的另一重要组成部分是缓存（又称为磁道缓冲区，大约 8 MB 或 16 MB），驱动器使用这些内存来保存从磁盘读取或写入磁盘的数据，从而令驱动器快速响应所有后续对同一数据块的请求。在向磁盘写入数据时，将数据写入缓存后就回报写入完成称为后写缓存/立即报告，将数据实际写入磁盘后才回报写入完成称为直写，后写缓存会使驱动器看起来更快，但可能有危险。</p>
<p>对于给定的一组 I/O 请求，可以由操作系统先通过 I/O 合并将连续的小请求块合并一个大请求块，再通过磁盘调度程序检查请求并决定下一个要调度的请求，磁盘调度程序通过估计请求的查找和可能的旋转延迟，可以很好估计每个请求任务大概需要多长时间，因此可以贪婪的选择先服务花费时间最少的请求，即遵循 SJF。此外，最短寻道时间优先（SSTF）按磁道对 I/O 请求队列排序，选择先服务最近磁道上的请求，但会有饥饿问题；最近块优先（NBF）选择先服务最近扇区块地址上的请求，同样会有饥饿问题。</p>
<p>在现代系统中，操作系统调度程序通常会选择它认为最好的几个请求，并将它们全部发送到磁盘，磁盘可以接受多个分离的请求，它们本身具有复杂的内部调度程序，可以利用磁头位置、详细的磁道布局信息、磁盘自身的寻道和旋转速度等内部知识，来很准确地通过最短定位时间优先（SPTF）选择先服务可以最先定位到的块（理论上最佳的请求）。</p>
<h3 id="5-1-3-磁盘阵列"><a href="#5-1-3-磁盘阵列" class="headerlink" title="5.1.3 磁盘阵列"></a>5.1.3 磁盘阵列</h3><p>随着需要存储的数据越来越多，I/O 操作可能成为拖慢整个系统的瓶颈，因此考虑廉价冗余磁盘阵列（RAID）技术。RAID 外部看起来像一个磁盘/一组可以读取或写入的块，内部实际使用多个磁盘、内存以及一个或多个处理器，并行使用多个磁盘可以大大加快 I/O 时间，此外通过某种形式的冗余，RAID 可以容许损失一个磁盘并保持运行，就像没有发生错误一样，因此，RAID 实现了一个更快、更大、更可靠的磁盘系统（其实就像一个专门用于管理一组磁盘的计算机系统，运行专门用于操作 RAID 的软件）。</p>
<p>当文件系统向 RAID 发出逻辑 I/O 请求时，RAID 内部计算要访问的磁盘，然后发出物理 I/O 以完成请求，每个逻辑读 I/O 对应一个物理读 I/O，每个逻辑写 I/O 对应 N 个物理写 I/O（N 为数据副本的个数）。RAID 以轮转方式将磁盘阵列的块分布在磁盘上，在对数组的连续块进行请求时，从阵列中可以获取最大的并行性，块越小，意味着许多文件将跨多个磁盘进行条带化，增加了对单个文件的读取和写入的并行性，但跨多个磁盘访问块的定位时间会增加。此外，RAID 可以透明地为主机系统服务，即可以简单地用 RAID 替换磁盘，而不需要更换一行软件，操作系统和客户端应用程序无须修改就可以继续运行。</p>
<h2 id="5-2-I-O-操作"><a href="#5-2-I-O-操作" class="headerlink" title="5.2 I/O 操作"></a>5.2 I/O 操作</h2><h3 id="5-2-1-基本概念"><a href="#5-2-1-基本概念" class="headerlink" title="5.2.1 基本概念"></a>5.2.1 基本概念</h3><p>主机的网络驱动接收到消息之后，会向内核申请空间，在收到完整的数据包后将其复制到磁盘或内核空间的缓存中。用户应用程序以用户模式运行，用户模式下的应用程序无法访问机器的硬件资源，不能发起对磁盘的 I/O 请求，不能访问任何物理内存页或在网络上发送数据包。</p>
<p>当应用程序需要进行 I/O 操作时，将会发起<strong>系统调用</strong>，此时控制权转移到预先设置的操作系统中，操作系统以<strong>内核模式</strong>运行，可以完全访问硬件资源，可以通过 DMA 把数据从磁盘拷贝到内核空间缓存区，然后 CPU 再把数据从内核空间拷贝到用户空间，对于 Java 程序还需要从堆外内存拷贝到堆内存。</p>
<p>当操作系统完成系统调用请求的服务时，将控制权交还给用应用程序，返回到用户模式，接着再由用户程序进行处理。</p>
<ul>
<li><p>系统调用非常强大，比如 UNIX 系统所采用的<code>fork()</code>、<code>wait()</code>及<code>exec()</code>这些系统调用可以很灵活创建和操作进程</p>
</li>
<li><p>零拷贝就是通过各种方式来减少 CPU 参与数据拷贝的次数，常见的零拷贝方式有 DMA、mmap、sendfile、direct I/O</p>
<ul>
<li>DMA (Direct Memory Access) 的作用就是直接将 I/O 设备的数据拷贝到内核缓冲区中，这个过程避免了 CPU 的参与</li>
<li>mmap (memory map，内存映射) 就是将内核态和用户态的内存映射到一起，避免来回拷贝，系统会自动将用户修改后的脏页回写到对应的磁盘上，内核的修改也会直接反映到用户，并实现不同用户进程之间的文件共享，既完成了对文件的读写操作又不必进行系统调用，但 mmap 使用时必须事先指定好的内存映射的大小，且必须要在内存中找到一块连续的地址块，不适合变长文件和超大文件</li>
<li>sendfile 只会做文件传输，而不通过用户态进行干预，即不需要进行涉及用户态的拷贝</li>
<li>direct I/O 指数据不经过内核态，而是由 I/O 设备直接拷贝到用户态的内存中，此时操作系统不再负责缓存之类的管理，这就必须交由应用程序自己去做</li>
</ul>
</li>
<li><p>同步与异步描述的是被调用者，阻塞和非阻塞描述的是调用者，同步异步与阻塞非阻塞之间没有必然关系</p>
<ul>
<li>同步指被调用者接到调用后立即执行，调用者的调用可以得到结果</li>
<li>异步指被调用者接到调用后仅保证会执行但不保证会立即执行，执行结束后会去通知调用者</li>
<li>阻塞指调用者在发出调用后需要一直等待直到被调用者执行完成</li>
<li>非阻塞指调用者在发出调用后不需要等待，可以去做自己的事情</li>
</ul>
</li>
</ul>
<h3 id="5-2-2-I-O-模型"><a href="#5-2-2-I-O-模型" class="headerlink" title="5.2.2 I/O 模型"></a>5.2.2 I/O 模型</h3><p>当用户进程需要进行 I/O 读操作时，将会经历1）发起系统调用，向内核发送读请求；2）内核向硬件发送读指令，并等待读就绪；3）DMA 将要读取的数据复制到指定的内核缓存区中；4）内核将数据从内核缓存区拷贝到用户进程空间中这些阶段，这整个过程可能使用五种不同的 I/O 模型。</p>
<ul>
<li><p>同步阻塞型 I/O 模型，从系统调用到数据从内核拷贝到用户空间并返回，这整个 I/O 操作过程中，用户进程始终都是阻塞</p>
</li>
<li><p>I/O 多路复用模型，多个进程 I/O 可以注册到同一个管道上，这个管道会统一和内核进行交互，本质上也是同步阻塞型 I/O，用户进程先调用 select、poll 或  epoll，select、poll 和  epoll 都会等数据到达内核（用户进程阻塞于 select 或 poll ）时返回，此时用户进程再发起系统调用等待数据从内核缓存区拷贝到用户进程空间中（非阻塞）</p>
</li>
<li><p>同步非阻塞型 I/O 模型，用户进程在系统调用后立即返回，用户进程定时轮询系统调用是否返回数据，只有在系统调用还未返回数据（即数据还未到达内核）时用户进程是非阻塞的，在数据到达内核缓存区后用户进程需要阻塞等待内核将数据从内核缓存区拷贝到用户进程空间中</p>
</li>
<li><p>信号驱动 I/O 模型，用户进程通过调用 sigaction 注册信号函数，等内核准备好数据（非阻塞）时中断当前用户进程，执行信号函数，此时用户进程再发起系统调用等待数据从内核缓存区拷贝到用户进程空间中（阻塞）</p>
</li>
<li><p>异步 I/O 模型，调用 aio_read 令内核把数据准备好并复制到用户空间，这整个 I/O 操作都完成后执行信号函数，通知用户进程 I/O 操作已经完成，用户进程全程都不关心具体 I/O 实现，始终都是异步非阻塞的</p>
</li>
</ul>
<p>注：select、poll、epoll 都是 Linux 中常见的 I/O 多路复用技术，可以用于同时监听多个文件描述符，当任意一个文件描述符就绪时，就能够非阻塞地读写数据</p>
<ul>
<li><p>select 是最原始的 I/O 多路复用技术，几乎在所有的平台中都支持，缺点是单个进程最多只能监听 1024 个文件描述符，需要遍历所有的文件描述符，开销随着文件描述符数量增加而线性增大</p>
</li>
<li><p>poll 在 select 的基础上增加了支持监听更多的文件描述符的能力，但需要遍历所有的文件描述符，开销随着文件描述符数量增加而线性增大</p>
</li>
<li><p>epoll 在 poll 的基础上进一步优化了复杂度，依旧可以支持更多的文件描述符，也不需要遍历所有的文件描述符，具有更高的效率</p>
</li>
</ul>
<h2 id="5-3-文件系统技术"><a href="#5-3-文件系统技术" class="headerlink" title="5.3 文件系统技术"></a>5.3 文件系统技术</h2><h3 id="5-3-1-文件和目录"><a href="#5-3-1-文件和目录" class="headerlink" title="5.3.1 文件和目录"></a>5.3.1 文件和目录</h3><p>存储虚拟化有两个关键的抽象</p>
<ul>
<li>文件<ul>
<li>文件是一个线性字节数组，每个字节都可以读写</li>
<li>每个文件都有一个用户可见名和一个用户不可见的 inode 号与之关联，</li>
<li>用户可见的文件名通常包含由<code>.</code>分隔的两部分，第一部分是任意名称，第二部分通常用于指示文件的类型</li>
<li>创建文件后会得到一个文件描述符，文件描述符是一个进程私有的整数，是一种权限/一个不透明的句柄/指向文件类型对象的指针，可以使用文件描述符来读写文件</li>
<li>对于每个进程打开的文件，操作系统都会跟踪一个“当前”偏移量，这将决定下一次读写开始时的位置</li>
</ul>
</li>
<li>目录<ul>
<li>每个目录也都有一个用户可见名和用户不可见的 inode 号与之关联</li>
<li>目录的内容非常具体，包含一个名字对（用户可读名和 inode 号）列表，列表中每个条目都指向文件或其他目录，从而构建目录树/目录层次结构</li>
<li>目录层次从根目录开始，并使用某种分隔符来命名后续子目录，目录和文件可以具有相同的名称，只要它们绝对路径名不同即可</li>
</ul>
</li>
</ul>
<p>文件系统为每个文件/目录保存一种持久数据结构 inode，inode 中保存了文件/目录的一些元数据信息（inode 号、大小、所有权、引用计数以及何时被修改等信息），inode 号在特定文件系统中是唯一的。操作系统并不了解文件的内部结构，仅仅只是通过文件系统将这些数据永久存储在磁盘上（文件系统技术大部分发展都是基于磁盘驱动器的行为），并确保再次请求数据时，得到原来存储的内容。</p>
<p>文件系统提供了一种统一的接口/方式（系统调用）来对位于磁盘、U 盘等其他设备上的文件/目录进行创建、重命名、访问、删除、文件读写等操作。但是目录的格式被视为文件系统元数据，因此永远不能直接写入目录，只能间接更新目录（比如在目录中创建文件、目录或其他对象类型）。可以有多个用户可见名连接到同一个 inode，那么在删除文件/目录时，其实是解除用户可见名和 inode 之间的连接，并减少 inode 的引用计数，只有 inode 的引用计数为零时，文件系统才会释放 inode 和相关数据块，从而真正“删除”文件。</p>
<h3 id="5-3-2-基本文件系统"><a href="#5-3-2-基本文件系统" class="headerlink" title="5.3.2 基本文件系统"></a>5.3.2 基本文件系统</h3><p>文件系统在磁盘上使用某种数据结构（块、树或其他对象）来组织其数据和元数据，并将进程所发出的系统调用映射到对该数据结构的操作上。文件系统中的大多数空间用于存放用户数据，存放用户数据的磁盘区域称为数据区域，存放文件的元数据信息（inode）的磁盘区域称为 inode 表，用于记录该特定文件系统信息的区域称为超级块，还有一部分区域用于记录 inode 或数据块是空闲还是已分配的。</p>
<p>在一个给定的磁盘分区上创建一个特定类型的文件系统时，可以通过将该文件系统挂载到另一个文件系统中，那么就可以将这两个文件系统树合并为一个，即可以统一在这台机器的文件系统树访问所有文件系统，而不是拥有多个独立的文件系统。挂载文件系统时，操作系统首先读取超级块，初始化各种参数，然后将该卷添加到文件系统树中。</p>
<p>当进程发出系统调用来打开某个文件时，文件系统首先需要从文件系统的根目录（记为<code>/</code>）开始遍历路径名，直到找到所需文件的 inode（这里的 I/O 量与路径名的长度成正比），获取文件的一些基本信息（根目录的 inode 是“众所周知”的），进行最后的权限检查，在每个进程的打开文件表中，为此进程分配一个文件描述符，并将它返回给用户（当文件被关闭时，文件描述符应该被释放，此处不涉及任何 I/O）。</p>
<p>从磁盘读取文件涉及到 3 次 I/O：读 inode，更新 inode 以及读取真正的数据块，从磁盘写入文件至少涉及到 5 次 I/O：读 inode，写 inode，读空闲块数据结构，更新空闲块数据结构以及写入真正的数据块（可能还需要更新父目录）。读取和写入可能是昂贵的，会导致许多磁盘 I/O，因此，大多数文件系统使用系统内存来缓存重要的块，读取时可能会直接命中缓存，写入时也可以延迟写入到磁盘。许多现代操作系统将虚拟内存页和文件系统缓存页集成到统一页面缓存中，从而在虚拟内存和文件系统之间更灵活地分配内存。</p>
<h3 id="5-3-3-快速文件系统"><a href="#5-3-3-快速文件系统" class="headerlink" title="5.3.3 快速文件系统"></a>5.3.3 快速文件系统</h3><p>快速文件系统（FFS）保持了与基本文件系统相同的接口，但具有不同的内部实现。FFS 令文件系统的结构和分配策略具有<strong>磁盘意识</strong>，即通过合适的数据结构将文件系统的数据高效组织起来，并使用高效的分配策略来为数据分配磁盘空间，从而提高性能。</p>
<p>FFS 将磁盘划分为一些分组，称为柱面组/块组，每个组中都有超级块的一个副本，并记录每组的 inode 和数据块是否已分配，FFS 将相关的数据放置在同一组中，尽量避免穿越磁盘的长时间寻道</p>
<ul>
<li>放置目录时，倾向于将目录数据和 inode 放在空闲较多的柱面组中</li>
<li>放置文件时，首先一般情况下确保将文件的数据块分配到与其 inode 相同的组中，防止 inode 和数据之间的长时间寻道，其次将位于同一目录中的所有文件，放在它们所在目录的柱面组中</li>
<li>有个例外是针对大文件，为了避免大文件将填满它首先放入的块组，FFS 会将一定数量的块分配到第一个块组，接着不断将文件的下一个”大“块放在另一个利用率低的块组中</li>
<li>针对容易导致块内部碎片的小文件，FFS 首先通过缓冲延迟写入小文件，针对无法延迟写入的情况则引入了子块来存放小文件，而不是直接使用磁盘的数据块，只有当所有子块的总空间达到磁盘数据块时，FFS 将子块的内从复制到数据块中，并释放子块以备将来使用</li>
</ul>
<h3 id="5-3-4-日志结构文件系统"><a href="#5-3-4-日志结构文件系统" class="headerlink" title="5.3.4 日志结构文件系统"></a>5.3.4 日志结构文件系统</h3><p>由于内存大小不断增长，可以尽可能在内存中缓存更多的数据，那么读取操作将尽可能地在缓存中进行处理，磁盘流量将大多由写入操作组成。日志结构文件系统（LFS）首先将所有更新（包括元数据）缓冲在内存段中，当段已满时，会在一次长时间的顺序传输中写入磁盘，并始终将段写入到磁盘的空闲位置（LFS 永远不会覆写现有数据），由于 LFS 每次写入的段很大且都是顺序写入，尽可能减少了那些难以优化的磁盘寻道和旋转成本，每次写入时的定位成本也由真正的数据传输所摊销，因此可以有效地使用磁盘，LFS 的性能接近其峰值。</p>
<p>LFS 会反复将最新版本的文件写入磁盘上的新位置，此过程在保持效率的同时，意味着会在整个磁盘分散旧版本的文件结构，这些旧版本可以进行跟踪保留并允许用户恢复旧文件版本（这样的文件系统称为版本控制文件系统），也可以当做是需要定期收集清理的垃圾，LFS 清理程序按段工作，从而为后续写入清理出大块空间。</p>
<h3 id="5-3-5-分布式文件系统"><a href="#5-3-5-分布式文件系统" class="headerlink" title="5.3.5 分布式文件系统"></a>5.3.5 分布式文件系统</h3><p>复杂的服务是利用成千上万台机器来提供的，单个机器、磁盘、网络和软件都会不时故障，分布式的核心在于通过机器间互相合作，可以构建一个看起来很少失败的系统服务。分布式 C/S 计算的首次使用之一，是在分布式文件系统领域，这种场景下，服务器负责将数据存储在其磁盘上，客户端文件系统通过网络请求文件服务器的数据，这种设置允许多个客户端之间轻松共享数据，也方便管理备份数据。</p>
<p>1）Sun 网络文件系统（NFS）在客户端和服务器之间采用无状态的通信消息格式，重点实现了简单快速的服务器崩溃恢复</p>
<ul>
<li>无状态指每个客户端都发送完成请求所需的所有信息，每个服务器都完全根据请求信息执行，客户端和服务器不需要状态就能够发送或者响应请求，双方都不关注不假设对方的当前状态</li>
<li>NFS 协议采用文件句柄来唯一地描述文件或目录，文件句柄有三个重要组件：卷标识符用于告知服务器请求指向哪个文件系统，inode 号告知服务器请求访问该分区中的哪个文件，世代号用于在复用 inode 号递增它从而确保具有旧文件句柄的客户端不会意外地访问新分配的文件</li>
<li>大多数 NFS 请求都是幂等的，这意味着操作执行多次的效果与执行一次效果相同，因此客户端能够在请求超时后简单重试请求（任何读操作都是幂等的，而更新操作必须仔细考虑是否具有幂等性）</li>
<li>为了提高客户端性能，客户端文件系统会在内存中缓存文件数据和元数据，并将其作为写入的缓冲区来延迟实际写入，这时多个客户端之间就会存在缓存一致性问题，因此客户端需要定期检查服务器文件元数据来确定缓存中的数据是否已更改，这种频繁的检查会限制服务器响应的客户端数量，从而限制可扩展性</li>
<li>NFS 是基于块的协议，执行的 I/O 与读写的大小成比例</li>
</ul>
<p>2）Andrew 文件系统（AFS ）通过全文件缓存和回调让客户端与服务器之间的交互尽可能的少，重点实现了良好的可扩展性，且客户端性能接近本地性能</p>
<ul>
<li>AFS 打开文件时，客户端通常会从服务器接收最新的一致副本，并在客户端的本地磁盘上进行全文件缓存，后续的文件读写操作将被重定向到本地文件系统而不与服务器进行通信</li>
<li>AFS 引入了回调的概念，当客户端缓存的文件被修改时，服务器将通知客户端，通过将此状态添加到服务器，客户端不再需要联系服务器已查明缓存的文件是否仍然有效，更不用依赖频繁的低级检查来确保缓存一致性</li>
<li>AFS 通过文件标识符（FID）替代路径名来指定客户端感兴趣的文件，FID 包括卷标识符、文件标识符和“全局唯一标识符”，因此服务器不需要沿着这个路径名来查找所需的文件，而是客户端沿着路径名查找并缓存结果，从而减少服务器上的负载</li>
<li>客户端崩溃重启后应当将所有的缓存视为可疑，主动向服务器询问缓存是否仍然有效，服务器崩溃重启后丢失了所有回调信息，此时需要主动通知所有的客户端将其所有本地缓存视为可疑，并且在使用之前重新检查文件有效性</li>
<li>AFS 是基于文件的协议，在进行小数据量的读写时依旧要整个文件的 I/O</li>
</ul>
<h2 id="5-4-存储可靠性"><a href="#5-4-存储可靠性" class="headerlink" title="5.4 存储可靠性"></a>5.4 存储可靠性</h2><h3 id="5-4-1-崩溃一致性"><a href="#5-4-1-崩溃一致性" class="headerlink" title="5.4.1 崩溃一致性"></a>5.4.1 崩溃一致性</h3><p>文件系统的数据结构必须持久存储在断电也能保留数据的设备上，根据上文，从磁盘写入文件至少涉及到 5 次 I/O（3 次写 I/O），磁盘一次只提交一次写入，那么当多次写 I/O 之间发生断电和崩溃时，就会导致崩溃一致性问题。</p>
<p>早期的文件系统通过阶段性运行 fsck 来查找并修复文件系统中的数据一致性问题，fsck 在文件系统挂载并可用之前运行，在 fsck 运行期间文件系统中没有其他活动正在进行，但随着磁盘卷容量的增长，fsck 扫描整个磁盘的时间逐渐变长，运行性能逐渐变差。许多现在文件系统都使用日志的方式来解决一致性问题（记录更新的确切物理内容的日志为物理日志，记录更新逻辑表达的日志称为逻辑日志，逻辑日志更加紧凑且复杂）。</p>
<p>更新磁盘时，在覆写结构之前，首先在磁盘的某个总所周知的位置写下一点小注记，描述将要做的希望保证原子性的事情，这个注记就是“预写”部分，注记写入某个结构就组织成了“日志”，并通过在日志的开始和结束块中加入包含日志内容的校验和，来确保在日志写入期间没有发生崩溃；接着将待处理的元数据和数据更新写入文件系统中的最终磁盘位置（这个过程称为加检查点）；最后通过日志文件系统释放已完成的事务在日志中占用的空间，从而允许重用日志空间（日志被视为循环数据结构）。</p>
<p>如果在写入日志期间发生崩溃，只需简单地跳过待执行的更新；如果在日志写入完成后加检查点完成前发生崩溃，文件系统将扫描日志，查找已提交到磁盘的日志事务（而不需要通过扫描整个磁盘来检查问题），然后这些事务被重放（在删除目录时会在日志中写入撤销记录，那么在重放日志时，任何被撤销的数据都不会被重放），文件系统再次尝试将事务中的块写入它们最终的磁盘位置。因为恢复是一种罕见的操作，所以这种设计上的冗余写入并不会造成坏影响。</p>
<p>这种记录了用户数据的日志（称为<strong>数据日志</strong>）使得每次写入磁盘的流量加倍，在写入日志和写入主文件系统之间，存在代价高昂的寻道，这为某些工作负载增加了显著的开销，因此考虑<strong>元数据日志/有序日志</strong>。元数据日志和数据日志的区别在于，直接将用户数据写入最终磁盘位置而不写入日志，只将元数据写入日志（这两步都完成后才视为日志写入完成，随后加元数据检查点……），即先写入被指对象，再写入指针。</p>
<h3 id="5-4-2-数据完整性"><a href="#5-4-2-数据完整性" class="headerlink" title="5.4.2 数据完整性"></a>5.4.2 数据完整性</h3><p>除了磁盘完全无法工作的崩溃情况，还有可能磁盘似乎可以正常工作但只是无法访问部分块或部分块保存了错误的内容。</p>
<p>现代存储系统用于保持数据完整性的主要机制称为校验和，校验和就是一个函数的结果，函数以一块数据作为输入，产生数据内容的小摘要，此摘要称为校验和（除了数据内容，还可以在校验和中添加更多的信息，比如磁盘号、扇区号等），校验和是现代系统中快速有效地检测讹误的常用方法。校验和和数据一起存储，数据和校验和被打包为磁盘的一个扇区大小一起写入，在访问时确认数据的当前校验和和原始存储值是否匹配，从而检测数据是否以某种方式被破坏或改变。存储校验和是在存储一种冗余信息，而冗余的存在是错误检测和恢复的关键。</p>
<h1 id="6、参考资料"><a href="#6、参考资料" class="headerlink" title="6、参考资料"></a>6、参考资料</h1><ul>
<li>《Operating Systems: Three Easy Pieces》</li>
</ul>
</section>
    <!-- Tags START -->
    
    <!-- Tags END -->
    <!-- NAV START -->
    
  <div class="nav-container">
    <!-- reverse left and right to put prev and next in a more logic postition -->
    
      <a class="nav-left" href="/2023/07/31/overview/">
        <span class="nav-arrow">← </span>
        
          Overview -
        
      </a>
    
    
      <a class="nav-right" href="/2023/08/22/week-52/">
        
          2023.8.21 - 2023.8.25
        
        <span class="nav-arrow"> →</span>
      </a>
    
  </div>

    <!-- NAV END -->
    <!-- 打赏 START -->
    
    <!-- 打赏 END -->
    <!-- 二维码 START -->
    
    <!-- 二维码 END -->
    
      <!-- Utterances START -->
      <div id="utterances"></div>
      <script src="https://utteranc.es/client.js"
        repo=""
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async></script>    
      <!-- Utterances END -->
    
  </article>
  <!-- Article END -->
  <!-- Catalog START -->
  
    <aside class="catalog-container">
  <div class="toc-main">
  
      
          <strong class="toc-title">OUTLINE</strong>
          <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#1%E3%80%81%E5%BC%95%E8%A8%80"><span class="toc-nav-text">1、引言</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#2%E3%80%81%E8%99%9A%E6%8B%9F%E5%8C%96-CPU"><span class="toc-nav-text">2、虚拟化 CPU</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-1-CPU-%E6%8E%A7%E5%88%B6%E6%9D%83"><span class="toc-nav-text">2.1 CPU 控制权</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-2-%E5%A4%9A%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6"><span class="toc-nav-text">2.2 多进程调度</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-3-%E5%A4%9A%E6%A0%B8-CPU-%E8%B0%83%E5%BA%A6"><span class="toc-nav-text">2.3 多核 CPU 调度</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-4-CPU-%E5%A4%9A%E7%BA%A7%E7%BC%93%E5%AD%98"><span class="toc-nav-text">2.4 CPU 多级缓存</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-5-%E6%80%A7%E8%83%BD%E8%A1%A1%E9%87%8F%E6%8C%87%E6%A0%87"><span class="toc-nav-text">2.5 性能衡量指标</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#3%E3%80%81%E8%99%9A%E6%8B%9F%E5%8C%96%E5%86%85%E5%AD%98"><span class="toc-nav-text">3、虚拟化内存</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#3-1-%E8%BF%9B%E7%A8%8B%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4"><span class="toc-nav-text">3.1 进程地址空间</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#3-2-%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86"><span class="toc-nav-text">3.2 空闲空间管理</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#3-3-%E7%A1%AC%E4%BB%B6%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2"><span class="toc-nav-text">3.3 硬件地址转换</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#3-3-1-MMU"><span class="toc-nav-text">3.3.1 MMU</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#3-3-2-%E5%88%86%E6%AE%B5"><span class="toc-nav-text">3.3.2 分段</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#3-3-3-%E5%88%86%E9%A1%B5"><span class="toc-nav-text">3.3.3 分页</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#3-3-4-TLB"><span class="toc-nav-text">3.3.4 TLB</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#3-3-5-%E5%B0%8F%E9%A1%B5%E8%A1%A8"><span class="toc-nav-text">3.3.5 小页表</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#3-4-%E6%9B%B4%E5%A4%A7%E5%AD%98%E5%82%A8%E7%A9%BA%E9%97%B4"><span class="toc-nav-text">3.4 更大存储空间</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#3-4-1-%E7%A1%AC%E7%9B%98%E8%AE%BE%E5%A4%87"><span class="toc-nav-text">3.4.1 硬盘设备</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#3-4-2-%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5"><span class="toc-nav-text">3.4.2 交换策略</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#4%E3%80%81%E5%B9%B6%E5%8F%91"><span class="toc-nav-text">4、并发</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#4-1-%E5%9F%BA%E4%BA%8E%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91"><span class="toc-nav-text">4.1 基于线程的并发</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#4-1-1-%E8%A7%84%E8%8C%83"><span class="toc-nav-text">4.1.1 规范</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#4-1-2-%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-nav-text">4.1.2 线程的实现</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#4-1-2-%E4%BA%92%E6%96%A5%E9%87%8F-%E9%94%81"><span class="toc-nav-text">4.1.2 互斥量&#x2F;锁</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#4-1-3-%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F"><span class="toc-nav-text">4.1.3 条件变量</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#4-1-4-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-nav-text">4.1.4 数据结构</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#4-2-%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91"><span class="toc-nav-text">4.2 基于事件的并发</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#5%E3%80%81%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-nav-text">5、持久化</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#5-1-I-O-%E8%AE%BE%E5%A4%87"><span class="toc-nav-text">5.1 I&#x2F;O 设备</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-1-1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-nav-text">5.1.1 基本概念</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-1-2-%E7%A3%81%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8"><span class="toc-nav-text">5.1.2 磁盘驱动器</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-1-3-%E7%A3%81%E7%9B%98%E9%98%B5%E5%88%97"><span class="toc-nav-text">5.1.3 磁盘阵列</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#5-2-I-O-%E6%93%8D%E4%BD%9C"><span class="toc-nav-text">5.2 I&#x2F;O 操作</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-2-1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-nav-text">5.2.1 基本概念</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-2-2-I-O-%E6%A8%A1%E5%9E%8B"><span class="toc-nav-text">5.2.2 I&#x2F;O 模型</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#5-3-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF"><span class="toc-nav-text">5.3 文件系统技术</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-3-1-%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95"><span class="toc-nav-text">5.3.1 文件和目录</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-3-2-%E5%9F%BA%E6%9C%AC%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F"><span class="toc-nav-text">5.3.2 基本文件系统</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-3-3-%E5%BF%AB%E9%80%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F"><span class="toc-nav-text">5.3.3 快速文件系统</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-3-4-%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F"><span class="toc-nav-text">5.3.4 日志结构文件系统</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-3-5-%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F"><span class="toc-nav-text">5.3.5 分布式文件系统</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#5-4-%E5%AD%98%E5%82%A8%E5%8F%AF%E9%9D%A0%E6%80%A7"><span class="toc-nav-text">5.4 存储可靠性</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-4-1-%E5%B4%A9%E6%BA%83%E4%B8%80%E8%87%B4%E6%80%A7"><span class="toc-nav-text">5.4.1 崩溃一致性</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-4-2-%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7"><span class="toc-nav-text">5.4.2 数据完整性</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#6%E3%80%81%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-nav-text">6、参考资料</span></a></li></ol>
      
  
  </div>
</aside>
  
  <!-- Catalog END -->
</main>

<script>
  (function () {
    var url = 'http://example.com/2023/08/20/operating-systems/';
    var banner = ''
    if (banner !== '' && banner !== 'undefined' && banner !== 'null') {
      $('#article-banner').css({
        'background-image': 'url(' + banner + ')'
      })
    } else {
      $('#article-banner').geopattern(url)
    }
    $('.header').removeClass('fixed-header')

    // error image
    $(".markdown-content img").on('error', function() {
      $(this).attr('src', '/css/images/error_icon.png')
      $(this).css({
        'cursor': 'default'
      })
    })

    // zoom image
    $(".markdown-content img").on('click', function() {
      var src = $(this).attr('src')
      if (src !== '/css/images/error_icon.png') {
        var imageW = $(this).width()
        var imageH = $(this).height()

        var zoom = ($(window).width() * 0.95 / imageW).toFixed(2)
        zoom = zoom < 1 ? 1 : zoom
        zoom = zoom > 2 ? 2 : zoom
        var transY = (($(window).height() - imageH) / 2).toFixed(2)

        $('body').append('<div class="image-view-wrap"><div class="image-view-inner"><img src="'+ src +'" /></div></div>')
        $('.image-view-wrap').addClass('wrap-active')
        $('.image-view-wrap img').css({
          'width': `${imageW}`,
          'transform': `translate3d(0, ${transY}px, 0) scale3d(${zoom}, ${zoom}, 1)`
        })
        $('html').css('overflow', 'hidden')

        $('.image-view-wrap').on('click', function() {
          $(this).remove()
          $('html').attr('style', '')
        })
      }
    })
  })();
</script>







    <div class="scroll-top">
  <span class="arrow-icon"></span>
</div>
    <footer class="app-footer">
  <p class="copyright">
    &copy; 2024 | Proudly powered by <a href="https://hexo.io" target="_blank">Hexo</a>
    <br>
    Theme by <a target="_blank" rel="noopener" href="https://github.com/yanm1ng">yanm1ng</a>
    
  </p>
</footer>

<script>
  function async(u, c) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }
</script>
<script>
  async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
    FastClick.attach(document.body);
  })
</script>

<script>
  var hasLine = 'true';
  async("//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js", function(){
    $('figure pre').each(function(i, block) {
      var figure = $(this).parents('figure');
      if (hasLine === 'false') {
        figure.find('.gutter').hide();
      }
      hljs.configure({useBR: true});
      var lang = figure.attr('class').split(' ')[1] || 'code';
      var codeHtml = $(this).html();
      var codeTag = document.createElement('code');
      codeTag.className = lang;
      codeTag.innerHTML = codeHtml;
      $(this).attr('class', '').empty().html(codeTag);
      figure.attr('data-lang', lang.toUpperCase());
      hljs.highlightBlock(block);
    });
  })
</script>
<!-- Baidu Tongji -->


<script src="/js/script.js"></script>


  </body>
</html>