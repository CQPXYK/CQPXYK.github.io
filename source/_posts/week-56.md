---
title: 2023.9.18 - 2023.9.22
date: 2023-09-23 15:05:35
password: 1062597351
tags:
---

> - 工作相关：Job Dispatcher & Message Queue
> - 博客更新：[Operating Systems](../../../../2023/08/20/operating-systems/)

### Architecture

这里存在一个消息生产和消费的模型，项目上游是消息生产方（产生待执行的 job），项目本身是消息消费方（执行待执行的 job），那么就对应两个负载均衡问题，一个是对大量待执行的 job 进行削峰填谷（这一点由消息缓存来实现），另一个是将待执行的 job 合理分发给分布在不同机器上的 service（这一点由 Job Dispatcher 和 Job Processor 之间的消息分发模型来实现）。

<img src="1.png" alt="" style="zoom:80%;" />

### Job Dispatcher

在基于一个已有的项目进行重构时，项目与上下游的交互方式需要保持不变，所以继续使用 DB 作为消息缓存，但是如果以后有新的项目需要设计，应该综合考虑一些专业的消息队列方案，根据实际业务量来选择最合适的一个。

<img src="2.png" alt="" style="zoom:80%;" />

数据库是为了存储大量数据而设计的，并提供了事务机制来保证数据的一致性，而消息队列则是为了高效地处理大量的消息而设计的。当数据吞吐量并不大时，简单的使用 DB 作为消息缓存即可满足要求；而在数据吞吐量较大的高并发场景下，DB 可能会成为瓶颈，影响性能（比如消息的生产者和消费者同时操作同一条记录，可能会产生死锁等问题，从而影响消息的可靠性）；如果业务量增长，需要处理的消息量也会增加，如果使用数据库作为消息队列的实现方式，可能需要进行水平扩展，增加数据库的数量，从而增加了维护和成本的复杂度。

RabbitMQ 由队列根据各种分发匹配规则来向消费端 push 消息，具备消息确认机制，适用于低吞吐量，消息路由复杂，需要确保可靠交付的场景，但需要学习比较复杂的接口和协议，学习、维护以及二次开发的成本较高。

Kafka 对消息分 topic，每一个 topic 再分区，每一个分区再由多个副本备份，本地磁盘顺序读写，由消费者 pull 消息，适用于流式大数据量高吞吐量实时处理，配置复杂，引入成本高。

RocketMQ 是淘宝采用 Java 参考 Kafka 产生的，同样具备良好的分布式以及消息堆积支持，适用于高并发场景，秒杀活动等，强大的功能必然基于复杂的架构，同样的引入成本高。

### Job Processor

由于使用 DB 作为消息缓存，所以只能由 Job Processor 来主动从 DB 拉数据。

<img src="3.png" alt="" style="zoom:80%;" />

在将待执行的 job 的提交给线程池异步执行时，额外设置了一个 JobMonitor 来监控所有 job 的执行是否完成并相应的更新 DB 中的 status，这里 JobMonitor 的思想就是设置一个守护线程，其开发有一些需要注意的细节如下，将来或许有更加规范合适的实现方式。

<img src="4.png" alt="" style="zoom:80%;" />

<img src="5.png" alt="" style="zoom:80%;" />





