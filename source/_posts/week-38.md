---
title: 2023.5.15 - 2023.5.19
date: 2023-05-19 19:40:19
password: 1062597351
tags:
---

> - 工作相关：Model Risk Team 年度工作总结（简单的 CRUD 也需要认真设计出高效完备的实现方案）
> - 基础巩固：[MySQL](../../../../2022/08/06/mysql/)、[ORACLE](../../../../2022/12/15/oracle/)、[Java Language](../../../../2022/05/08/java-language/)

即将结束在 Model Risk Teams 的一年，现对这一年所做的比较有启发性的工作进行总结梳理，主要是应用程序和数据库交互这方面的功能实现和优化。

### 查询优化

Model Risk Management System 顾名思义就是模型管理，validator 会针对模型的缺陷给 sponsor 提出对应的 limitation，MRMS 有个页面需要加载并显示当前用户权限所能访问到的 limitation 条目。

现有处理逻辑是后端通过一个大的查询 SQL 和一系列 Java 逻辑处理返回所有 limitation，由前端进行分页，并在页面上通过一个 grid 显示出来，随着 limitation 数据越来越多，有些用户的页面加载耗时长达一分钟，用户要求对这个页面加载进行优化。

优化分为以下几个步骤：

- 将 Java 代码中的过滤逻辑前置到查询 SQL 当中，SQL 逻辑会变的更加复杂，但可以避免数据库返回不必要的数据
  - 经过测试，带来的效果是对于过滤量比较大的用户，请求会快很多，但是对于过滤量比较小的用户，请求会比之前更慢，这个结果与理论是相符的
- 将前端分页改成后端分页，后端不必一次性返回庞大的完整数据，但在页面做的所有操作（翻页，过滤，排序）都需要重新查询并返回新的分页结果
  - 经过测试，虽然需要加载的次数变多，但每次加载时间被缩减为一两秒，用户表示可以接受
- 将与分页无关的长字符串拼接逻辑后置到 Java 代码中，避免数据库拼接并返回长字符串
  - 原本做到上一步优化的目的就已经达成，但是后来出了一个 prod issue，root cause 是在查询 SQL 中有一个使用 listagg 来进行的字段拼接的逻辑，当拼接的长度超过 4000 个字符的限制时，SQL 的执行会出错，进而导致页面加载不出来
  - 为了解决这个问题，将这个字符串拼接的逻辑后置到 Java 代码中，测试的时候发现性能同时也有所提升，证明了数据库拼接并返回长字符串是比较耗时的，长字符串拼接逻辑由 Java 代码在应用程序中实现更为合适
  - 经过测试，优化后的页面加载时间平均在6、7秒左右

这只是一个工作量比较大的查询优化相关的需求举例，除此以外还做了一些其他的查询优化相关的小需求，究其根本都是在尽量避免数据库返回太多不必要的数据，减少冗余的操作。

### 上游数据解析落库

有两个上游系统分别通过 SFTP 和用户上传来提供上游数据，针对 SFTP 的方式需要一个 AutoSys Job 和一个脚本来定时从 SFTP 拿文件并调用 API 进行解析和落库，针对用户上传的方式需要提供一个前端页面来接收上传文件并调用 API 进行解析和落库。

POC 的实现思路如下：

- 针对两个上游系统所提供的数据，在拿到数据文件之后，共同的逻辑是解析和落库，使用模板方法模式以及 Java 泛型，抽象出`ParseTemplate`和`LoadTemplate`，在模板抽象类中编写共通的逻辑骨架

- 针对上游提供的不同的数据文件，使用策略模式，编写不同文件类型所对应的由`ParseTemplate`基类派生出解析策略类，根据传入的文件类型动态选择对应的解析策略

- 针对解析得到的上游数据，与 DB 中现有的数据进行对比，对需要删除的数据给删除标记位赋值进行软删除，调用 JPA 的`saveAll`接口进行落库

  

在和各位 lead 进行 tech review 时，提出了以下建议：

- 当需要进行落库的数据集较大，执行时间较长时，考虑将数据集分为多个小型数据集，异步分批多次 commit 来进行落库

- 增加上游数据落库相关的邮件通知，便于 support 和 dev 监控每天的落库是否正常执行，让 user 能够及时清楚的了解到数据变化明细

- 更新 Reference 表的同时，希望再更新维护一个 History 表，用以记录对 Reference 表的所有 DML 操作信息

  

对 tech review 的建议的思考和实现思路如下：

- 异步分批 DML 可以节省时间也降低风险，此外也是希望从根本上将 DML 操作完全交由给子线程去执行，主线程可以直接返回，避免 AutoSys Job 长时间阻塞，而对于 AutoSys Job 和直接返回的主线程来说，无法得知那些异步执行的逻辑后续是否执行成功，所以还需要邮件通知异步落库的最终执行情况甚至是脚本的执行日志等，便于追踪和排查问题

- 关于邮件通知的触发是通过切面来实现的，在被拦截方法执行之后根据方法的执行情况判断需要触发何种类型的邮件通知，其实一开始我想到的思路是观察者模式，但是由于这里观察者 Observer 只有邮件通知 Service 这一个而已，那么直接使用切面并在切面代码中调用邮件通知 Service 即可，感觉观察者模式应该更适用于存在多个被观察者和多个观察者这种多对多的复杂情况

- 维护 History 表有两种实现方式，一种是对 Reference 表加一个触发器，另一种是在 Java 代码中同时更新 Reference 表和 History 表，考虑到在 History 表中数据逐渐增大的过程中，DML（其实只有增操作）会越来越慢（表的索引随着表数据的增加而日益增大，同事索引的离散度比较高，oracle 在进行 index block 的读取时，可能无法命中缓存，导致需要进行物理读，势必会导致性能问题的出现），如果使用触发器来进行 History 表的 DML 则会影响 Reference 表（增删改都有，主要是改操作）的 DML 效率，因此还是由 Java 代码来实现，对 History 表的 DML 不会影响 Reference 表的 DML

  

对需求思维上的一些思考如下：

- 需要落库的上游数据集很大，也无法确保数据集中的数据本身是否存在问题，自己刚开始做 POC 的时候倾向于比较简单的处理方式，在处理上游数据集时，对于非阻塞性的数据问题直接跳过，阻塞性的数据问题直接抛出异常并提前结束，在开会讨论时被同事提醒不应该这样做

- 首先不管是否是阻塞性的数据问题，问题多少，都应当事无巨细地记录下来，通过邮件或者数据库的方式留存关于数据源的问题记录，这样才便于在出现业务问题时追踪原因

- 其次不管是否存在数据问题，问题大小，都不应该简单粗暴的直接抛出异常，不应该中断后续对其他数据的处理，才能尽可能减少对业务的影响范围和程度（凡是能够预判出的可能存在的问题，都应当进行相应的处理，而非仅仅是抛出异常）

- 不要预设对方会做出合规的行为，尽可能保留对外部数据的不信任感，在落库之前尽可能增加对外部数据的校验和预处理，尽可能做全面的容错处理

- 简单没有错，但应当追求的简单的方案，而非简单的功能，理想状态是为复杂强大的功能设计出简单高效的方案

  

### 落库（增删改）优化

截止目前只是完成了解析和落库的功能实现，但由于数据量太大，即使是异步分批的进行落库，耗时依旧长达四个多小时，因此考虑对落库处理进行优化。

优化分为以下几个步骤：

- 借助一张空的中介表，将解析出的上游数据直接批量插入（insert all）到该中介表中，批量插入时不再直接调用`saveAll`接口，而是通过获取数据连接来直接执行原生 SQL，经过测试，批量插入可以在几十秒内完成，性能远远优于 JPA 的`saveAll`接口

- 继续通过执行 SQL 来进行中介表和实际表之间的数据对比、实际表的数据更新（使用 merge into 而不是 update）以及历史表的更新记录（insert），经过测试，merge into 可以在几十秒内完成实际表的数据更新，性能远远优于`saveAll`和批量更新

  

经过测试，优化后的落库操作可以在两三分钟内完成，该优化的本质在于：

- 避免了从数据库返回大量的现有数据，而是直接将新数据导入到数据库中，将数据对比和更新逻辑从 Java 后置到 SQL 中完成

- 直接执行 insert all 来向数据库导入数据，JPA 的`saveAll`实际上会在`for`循环中逐个执行`save`，而每次`save`又涉及到两次和数据库的交互（具体见源码），显然效率会比直接在数据库中执行 insert all 更低

- 利用了 merge into 高效的执行计划，从下图所示的 update 和 merge into 的执行计划可知

  - update 在 hash join 后选择要更新的数据行，对于驱动表中要更新的每个数据行，都会执行关联更新的子查询，都会对匹配表重新扫描，相当于有个循环反复扫描匹配表的过程，效率会大大降低

    <img src="update.png" alt="update" style="zoom:80%;" />

  - merge into 在 hash join 后直接一次性更新，对驱动表和匹配表都只是分别做了一次全表扫描，不存在循环扫描匹配表，效率更高

    <img src="merge into.png" alt="merge into" style="zoom:80%;" />

查询优化和落库优化的区别在于功能方向不同，一个是要从数据库导出数据，一个是要向数据库导入数据，这种根本上的功能方向不同，就决定了优化方向不同，思考功能的最终落点在哪里，才能明确不必要的兜圈子在哪里，进而有针对性的进行优化。

### 感想和期望

所有不便测试的代码其实都是不够整洁的代码，而足够整洁的代码也都能比较方便的进行测试，TDD 能够督促自己编写整洁的代码。

我现在能确定的范围是 Java 后端，在这个范围里的我都愿意去接触和学习，至于不在这个范围里的内容，比如其他技术栈应该是需要在几年之后才去学习的内容，需要等到 Java 相关的知识点至少学了八成以后。

跟比较 senior 的同事讨论问题时总是有一种“原来可以这样，我怎么就没想到”的感觉，这种感觉非常好，所以我倾向于这种工作氛围。

最大的障碍在于我自己都不清楚自己的问题在哪里，有时候事情做得不对，但自己意识不到，所以很需要资历深有经验的同事盯着我，及时告诉我哪里做的不对。

我只看到了问题A和导致问题A的原因，但同事就能通过问题A进一步发现导致问题A的根本问题B，问题B不仅仅导致了问题A，还会触发一些其他问题CDE，此时再去研究导致问题B的原因。也就是说，我是直接从当前问题就开始追溯原因，而同事会从当前问题先追溯更根本的问题，再从根本问题扩展一系列衍生问题，预估影响，通知上下游，再追溯导致根本问题的原因，最后提出解决方案和后续预防方案。

关于通过 SFTP 获取数据文件的部分，组里没有现成可供参考的以往示例，所以很多问题都只能靠自己摸索，摸索到没有头绪的时候就开始试图找各种其他组的人请教，并不存在一个能够完整解答完我所有问题的人，也不存在一个完全可以给我照猫画虎的现成的方案，但是找的每一个人和每一个不算完整的方案，都能解答我的一部分疑惑，或者是带给我一些新的思路和启发，当我问的人足够多，尝试的思路足够多，就能一点点构建出我想要的。

